{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#séparation des données df_classification_binaire.csv (avec Nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>...</th>\n",
       "      <th>INSTAL_AMT_INSTALMENT_MEAN</th>\n",
       "      <th>INSTAL_AMT_INSTALMENT_SUM</th>\n",
       "      <th>INSTAL_AMT_PAYMENT_MIN</th>\n",
       "      <th>INSTAL_AMT_PAYMENT_MAX</th>\n",
       "      <th>INSTAL_AMT_PAYMENT_MEAN</th>\n",
       "      <th>INSTAL_AMT_PAYMENT_SUM</th>\n",
       "      <th>INSTAL_DAYS_ENTRY_PAYMENT_MAX</th>\n",
       "      <th>INSTAL_DAYS_ENTRY_PAYMENT_MEAN</th>\n",
       "      <th>INSTAL_DAYS_ENTRY_PAYMENT_SUM</th>\n",
       "      <th>INSTAL_COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>351000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11559.247105</td>\n",
       "      <td>219625.695</td>\n",
       "      <td>9251.775</td>\n",
       "      <td>53093.745</td>\n",
       "      <td>11559.247105</td>\n",
       "      <td>219625.695</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>-315.421053</td>\n",
       "      <td>-5993.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>1129500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64754.586000</td>\n",
       "      <td>1618864.650</td>\n",
       "      <td>6662.970</td>\n",
       "      <td>560835.360</td>\n",
       "      <td>64754.586000</td>\n",
       "      <td>1618864.650</td>\n",
       "      <td>-544.0</td>\n",
       "      <td>-1385.320000</td>\n",
       "      <td>-34633.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7096.155000</td>\n",
       "      <td>21288.465</td>\n",
       "      <td>5357.250</td>\n",
       "      <td>10573.965</td>\n",
       "      <td>7096.155000</td>\n",
       "      <td>21288.465</td>\n",
       "      <td>-727.0</td>\n",
       "      <td>-761.666667</td>\n",
       "      <td>-2285.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>297000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>62947.088438</td>\n",
       "      <td>1007153.415</td>\n",
       "      <td>2482.920</td>\n",
       "      <td>691786.890</td>\n",
       "      <td>62947.088438</td>\n",
       "      <td>1007153.415</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-271.625000</td>\n",
       "      <td>-4346.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12666.444545</td>\n",
       "      <td>835985.340</td>\n",
       "      <td>0.180</td>\n",
       "      <td>22678.785</td>\n",
       "      <td>12214.060227</td>\n",
       "      <td>806127.975</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-1032.242424</td>\n",
       "      <td>-68128.0</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307502</th>\n",
       "      <td>456251</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>254700.0</td>\n",
       "      <td>27558.0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7492.924286</td>\n",
       "      <td>52450.470</td>\n",
       "      <td>6605.910</td>\n",
       "      <td>12815.010</td>\n",
       "      <td>7492.924286</td>\n",
       "      <td>52450.470</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>-156.285714</td>\n",
       "      <td>-1094.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307503</th>\n",
       "      <td>456252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>269550.0</td>\n",
       "      <td>12001.5</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10069.867500</td>\n",
       "      <td>60419.205</td>\n",
       "      <td>10046.880</td>\n",
       "      <td>10074.465</td>\n",
       "      <td>10069.867500</td>\n",
       "      <td>60419.205</td>\n",
       "      <td>-2327.0</td>\n",
       "      <td>-2393.833333</td>\n",
       "      <td>-14363.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307504</th>\n",
       "      <td>456253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153000.0</td>\n",
       "      <td>677664.0</td>\n",
       "      <td>29979.0</td>\n",
       "      <td>585000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4399.707857</td>\n",
       "      <td>61595.910</td>\n",
       "      <td>27.270</td>\n",
       "      <td>5575.185</td>\n",
       "      <td>4115.915357</td>\n",
       "      <td>57622.815</td>\n",
       "      <td>-1738.0</td>\n",
       "      <td>-2387.428571</td>\n",
       "      <td>-33424.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307505</th>\n",
       "      <td>456254</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171000.0</td>\n",
       "      <td>370107.0</td>\n",
       "      <td>20205.0</td>\n",
       "      <td>319500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10239.832895</td>\n",
       "      <td>194556.825</td>\n",
       "      <td>2296.440</td>\n",
       "      <td>19065.825</td>\n",
       "      <td>10239.832895</td>\n",
       "      <td>194556.825</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>-161.263158</td>\n",
       "      <td>-3064.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307506</th>\n",
       "      <td>456255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>49117.5</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41464.713649</td>\n",
       "      <td>3068388.810</td>\n",
       "      <td>34.965</td>\n",
       "      <td>669251.655</td>\n",
       "      <td>47646.215878</td>\n",
       "      <td>3525819.975</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>-472.013514</td>\n",
       "      <td>-34929.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>307507 rows × 626 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SK_ID_CURR  TARGET  CODE_GENDER  FLAG_OWN_CAR  FLAG_OWN_REALTY  \\\n",
       "0           100002     1.0            0             0                0   \n",
       "1           100003     0.0            1             0                1   \n",
       "2           100004     0.0            0             1                0   \n",
       "3           100006     0.0            1             0                0   \n",
       "4           100007     0.0            0             0                0   \n",
       "...            ...     ...          ...           ...              ...   \n",
       "307502      456251     0.0            0             0                1   \n",
       "307503      456252     0.0            1             0                0   \n",
       "307504      456253     0.0            1             0                0   \n",
       "307505      456254     1.0            1             0                0   \n",
       "307506      456255     0.0            1             0                1   \n",
       "\n",
       "        CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0                  0          202500.0    406597.5      24700.5   \n",
       "1                  0          270000.0   1293502.5      35698.5   \n",
       "2                  0           67500.0    135000.0       6750.0   \n",
       "3                  0          135000.0    312682.5      29686.5   \n",
       "4                  0          121500.0    513000.0      21865.5   \n",
       "...              ...               ...         ...          ...   \n",
       "307502             0          157500.0    254700.0      27558.0   \n",
       "307503             0           72000.0    269550.0      12001.5   \n",
       "307504             0          153000.0    677664.0      29979.0   \n",
       "307505             0          171000.0    370107.0      20205.0   \n",
       "307506             0          157500.0    675000.0      49117.5   \n",
       "\n",
       "        AMT_GOODS_PRICE  ...  INSTAL_AMT_INSTALMENT_MEAN  \\\n",
       "0              351000.0  ...                11559.247105   \n",
       "1             1129500.0  ...                64754.586000   \n",
       "2              135000.0  ...                 7096.155000   \n",
       "3              297000.0  ...                62947.088438   \n",
       "4              513000.0  ...                12666.444545   \n",
       "...                 ...  ...                         ...   \n",
       "307502         225000.0  ...                 7492.924286   \n",
       "307503         225000.0  ...                10069.867500   \n",
       "307504         585000.0  ...                 4399.707857   \n",
       "307505         319500.0  ...                10239.832895   \n",
       "307506         675000.0  ...                41464.713649   \n",
       "\n",
       "        INSTAL_AMT_INSTALMENT_SUM  INSTAL_AMT_PAYMENT_MIN  \\\n",
       "0                      219625.695                9251.775   \n",
       "1                     1618864.650                6662.970   \n",
       "2                       21288.465                5357.250   \n",
       "3                     1007153.415                2482.920   \n",
       "4                      835985.340                   0.180   \n",
       "...                           ...                     ...   \n",
       "307502                  52450.470                6605.910   \n",
       "307503                  60419.205               10046.880   \n",
       "307504                  61595.910                  27.270   \n",
       "307505                 194556.825                2296.440   \n",
       "307506                3068388.810                  34.965   \n",
       "\n",
       "        INSTAL_AMT_PAYMENT_MAX  INSTAL_AMT_PAYMENT_MEAN  \\\n",
       "0                    53093.745             11559.247105   \n",
       "1                   560835.360             64754.586000   \n",
       "2                    10573.965              7096.155000   \n",
       "3                   691786.890             62947.088438   \n",
       "4                    22678.785             12214.060227   \n",
       "...                        ...                      ...   \n",
       "307502               12815.010              7492.924286   \n",
       "307503               10074.465             10069.867500   \n",
       "307504                5575.185              4115.915357   \n",
       "307505               19065.825             10239.832895   \n",
       "307506              669251.655             47646.215878   \n",
       "\n",
       "        INSTAL_AMT_PAYMENT_SUM  INSTAL_DAYS_ENTRY_PAYMENT_MAX  \\\n",
       "0                   219625.695                          -49.0   \n",
       "1                  1618864.650                         -544.0   \n",
       "2                    21288.465                         -727.0   \n",
       "3                  1007153.415                          -12.0   \n",
       "4                   806127.975                          -14.0   \n",
       "...                        ...                            ...   \n",
       "307502               52450.470                          -38.0   \n",
       "307503               60419.205                        -2327.0   \n",
       "307504               57622.815                        -1738.0   \n",
       "307505              194556.825                          -18.0   \n",
       "307506             3525819.975                          -76.0   \n",
       "\n",
       "        INSTAL_DAYS_ENTRY_PAYMENT_MEAN  INSTAL_DAYS_ENTRY_PAYMENT_SUM  \\\n",
       "0                          -315.421053                        -5993.0   \n",
       "1                         -1385.320000                       -34633.0   \n",
       "2                          -761.666667                        -2285.0   \n",
       "3                          -271.625000                        -4346.0   \n",
       "4                         -1032.242424                       -68128.0   \n",
       "...                                ...                            ...   \n",
       "307502                     -156.285714                        -1094.0   \n",
       "307503                    -2393.833333                       -14363.0   \n",
       "307504                    -2387.428571                       -33424.0   \n",
       "307505                     -161.263158                        -3064.0   \n",
       "307506                     -472.013514                       -34929.0   \n",
       "\n",
       "        INSTAL_COUNT  \n",
       "0               19.0  \n",
       "1               25.0  \n",
       "2                3.0  \n",
       "3               16.0  \n",
       "4               66.0  \n",
       "...              ...  \n",
       "307502           7.0  \n",
       "307503           6.0  \n",
       "307504          14.0  \n",
       "307505          19.0  \n",
       "307506          74.0  \n",
       "\n",
       "[307507 rows x 626 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('df_classification_binaire.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de NaN par colonne :\n",
      " SK_ID_CURR                            0\n",
      "TARGET                                0\n",
      "CODE_GENDER                           0\n",
      "FLAG_OWN_CAR                          0\n",
      "FLAG_OWN_REALTY                       0\n",
      "                                  ...  \n",
      "INSTAL_AMT_PAYMENT_SUM            15868\n",
      "INSTAL_DAYS_ENTRY_PAYMENT_MAX     15876\n",
      "INSTAL_DAYS_ENTRY_PAYMENT_MEAN    15876\n",
      "INSTAL_DAYS_ENTRY_PAYMENT_SUM     15868\n",
      "INSTAL_COUNT                      15868\n",
      "Length: 626, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Afficher le nombre de NaN par colonne\n",
    "nan_counts = df.isna().sum()\n",
    "print(\"Nombre de NaN par colonne :\\n\", nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du jeu d'entraînement : (304431, 626)\n",
      "Taille du jeu de test : (3076, 626)\n"
     ]
    }
   ],
   "source": [
    "#division initiale des données : 99% pour train (train_initial et final) et 1% pour X_nouveaux_clients (test)\n",
    "#un sample sera pris des 90% pour la recherche des hyperparametres\n",
    "#le model final sera entrainé sur toutes les données le 100% des 90%\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Séparer 1% des données pour le test en utilisant la stratification\n",
    "df_train, df_test = train_test_split(\n",
    "    df, \n",
    "    test_size=0.01, \n",
    "    random_state=42, \n",
    "    stratify=df['TARGET']\n",
    ")\n",
    "\n",
    "# Vérification des dimensions des jeux de données\n",
    "print(f\"Taille du jeu d'entraînement : {df_train.shape}\")\n",
    "print(f\"Taille du jeu de test : {df_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_csv('df_train.csv', index=False)\n",
    "df_test.to_csv('df_test.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de X_train_eval: (30443, 625)\n",
      "Taille de y_train_eval: (30443,)\n",
      "Taille de X_api: (3076, 625)\n",
      "Taille de y_api: (3076,)\n",
      "Taille de X_final: (304431, 625)\n",
      "Taille de y_final: (304431,)\n"
     ]
    }
   ],
   "source": [
    "#pour le df_test\n",
    "# Séparer les features (X) et la cible (y)\n",
    "X_api = df_test.drop(columns=['TARGET'])  \n",
    "y_api = df_test['TARGET']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#pour df_train\n",
    "\n",
    "# Séparation de 10% de df_train pour la recherche d'hyperparamètres\n",
    "df_train_param, df_unused = train_test_split(df_train, test_size=0.9, stratify=df_train['TARGET'], random_state=42)\n",
    "\n",
    "# Séparation des caractéristiques (X) et de la cible (y)\n",
    "X_train_eval = df_train_param.drop(columns='TARGET')\n",
    "y_train_eval = df_train_param['TARGET']\n",
    "X_final = df_train.drop(columns='TARGET')\n",
    "y_final = df_train['TARGET']\n",
    "\n",
    "# Vérification des dimensions pour confirmation\n",
    "print(\"Taille de X_train_eval:\", X_train_eval.shape)\n",
    "print(\"Taille de y_train_eval:\", y_train_eval.shape)\n",
    "print(\"Taille de X_api:\", X_api.shape)\n",
    "print(\"Taille de y_api:\", y_api.shape)\n",
    "print(\"Taille de X_final:\", X_final.shape)\n",
    "print(\"Taille de y_final:\", y_final.shape)\n",
    "\n",
    "# X_train_eval et y_train_eval : Utilisés pour l'entraînement et la validation des modèles\n",
    "# X_api et y_api : Échantillon pour tester l'API\n",
    "# X_final et y_final : Jeu de données final pour évaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#séparation des données df_clean_imputed.csv (sans Nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "import pandas as pd\n",
    "df = pd.read_csv('df_clean_imputed.csv')\n",
    "df\n",
    "\n",
    "# Afficher le nombre de NaN par colonne\n",
    "nan_counts = df.isna().sum()\n",
    "print(\"Nombre de NaN par colonne :\\n\", nan_counts)\n",
    "\n",
    "#division initiale des données : 99% pour train (train_initial et final) et 1% pour X_nouveaux_clients (test)\n",
    "#un sample sera pris des 90% pour la recherche des hyperparametres\n",
    "#le model final sera entrainé sur toutes les données le 100% des 90%\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Séparer 1% des données pour le test en utilisant la stratification\n",
    "df_train, df_test = train_test_split(\n",
    "    df, \n",
    "    test_size=0.01, \n",
    "    random_state=42, \n",
    "    stratify=df['TARGET']\n",
    ")\n",
    "\n",
    "# Vérification des dimensions des jeux de données\n",
    "print(f\"Taille du jeu d'entraînement : {df_train.shape}\")\n",
    "print(f\"Taille du jeu de test : {df_test.shape}\")\n",
    "\n",
    "df_train.to_csv('df_train_i.csv', index=False)\n",
    "df_test.to_csv('df_test_i.csv', index=False)\n",
    "\n",
    "#pour le df_test\n",
    "# Séparer les features (X) et la cible (y)\n",
    "X_api = df_test.drop(columns=['TARGET'])  \n",
    "y_api = df_test['TARGET']\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "#pour df_train\n",
    "\n",
    "# Séparation de 10% de df_train pour la recherche d'hyperparamètres\n",
    "df_train_eval, df_unused = train_test_split(df_train, test_size=0.9, stratify=df_train['TARGET'], random_state=42)\n",
    "\n",
    "# Séparation des caractéristiques (X) et de la cible (y)\n",
    "X_train_eval = df_train_eval.drop(columns='TARGET')\n",
    "y_train_eval = df_train_eval['TARGET']\n",
    "X_final = df_train.drop(columns='TARGET')\n",
    "y_final = df_train['TARGET']\n",
    "\n",
    "# Vérification des dimensions pour confirmation\n",
    "print(\"Taille de X_train_eval:\", X_train_eval.shape)\n",
    "print(\"Taille de y_train_eval:\", y_train_eval.shape)\n",
    "print(\"Taille de X_api:\", X_api.shape)\n",
    "print(\"Taille de y_api:\", y_api.shape)\n",
    "print(\"Taille de X_final:\", X_final.shape)\n",
    "print(\"Taille de y_final:\", y_final.shape)\n",
    "\n",
    "# X_train_eval et y_train_eval : Utilisés pour l'entraînement et la validation des modèles\n",
    "# X_api et y_api : Échantillon pour tester l'API\n",
    "# X_final et y_final : Jeu de données final pour évaluation\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>TARGET</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>...</th>\n",
       "      <th>INSTAL_AMT_INSTALMENT_MEAN</th>\n",
       "      <th>INSTAL_AMT_INSTALMENT_SUM</th>\n",
       "      <th>INSTAL_AMT_PAYMENT_MIN</th>\n",
       "      <th>INSTAL_AMT_PAYMENT_MAX</th>\n",
       "      <th>INSTAL_AMT_PAYMENT_MEAN</th>\n",
       "      <th>INSTAL_AMT_PAYMENT_SUM</th>\n",
       "      <th>INSTAL_DAYS_ENTRY_PAYMENT_MAX</th>\n",
       "      <th>INSTAL_DAYS_ENTRY_PAYMENT_MEAN</th>\n",
       "      <th>INSTAL_DAYS_ENTRY_PAYMENT_SUM</th>\n",
       "      <th>INSTAL_COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100002</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>406597.5</td>\n",
       "      <td>24700.5</td>\n",
       "      <td>351000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11559.247105</td>\n",
       "      <td>219625.695</td>\n",
       "      <td>9251.775</td>\n",
       "      <td>53093.745</td>\n",
       "      <td>11559.247105</td>\n",
       "      <td>219625.695</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>-315.421053</td>\n",
       "      <td>-5993.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100003</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>270000.0</td>\n",
       "      <td>1293502.5</td>\n",
       "      <td>35698.5</td>\n",
       "      <td>1129500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>64754.586000</td>\n",
       "      <td>1618864.650</td>\n",
       "      <td>6662.970</td>\n",
       "      <td>560835.360</td>\n",
       "      <td>64754.586000</td>\n",
       "      <td>1618864.650</td>\n",
       "      <td>-544.0</td>\n",
       "      <td>-1385.320000</td>\n",
       "      <td>-34633.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100004</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>67500.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>6750.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7096.155000</td>\n",
       "      <td>21288.465</td>\n",
       "      <td>5357.250</td>\n",
       "      <td>10573.965</td>\n",
       "      <td>7096.155000</td>\n",
       "      <td>21288.465</td>\n",
       "      <td>-727.0</td>\n",
       "      <td>-761.666667</td>\n",
       "      <td>-2285.0</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100006</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>312682.5</td>\n",
       "      <td>29686.5</td>\n",
       "      <td>297000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>62947.088438</td>\n",
       "      <td>1007153.415</td>\n",
       "      <td>2482.920</td>\n",
       "      <td>691786.890</td>\n",
       "      <td>62947.088438</td>\n",
       "      <td>1007153.415</td>\n",
       "      <td>-12.0</td>\n",
       "      <td>-271.625000</td>\n",
       "      <td>-4346.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100007</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>121500.0</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>21865.5</td>\n",
       "      <td>513000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12666.444545</td>\n",
       "      <td>835985.340</td>\n",
       "      <td>0.180</td>\n",
       "      <td>22678.785</td>\n",
       "      <td>12214.060227</td>\n",
       "      <td>806127.975</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>-1032.242424</td>\n",
       "      <td>-68128.0</td>\n",
       "      <td>66.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307502</th>\n",
       "      <td>456251</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>254700.0</td>\n",
       "      <td>27558.0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7492.924286</td>\n",
       "      <td>52450.470</td>\n",
       "      <td>6605.910</td>\n",
       "      <td>12815.010</td>\n",
       "      <td>7492.924286</td>\n",
       "      <td>52450.470</td>\n",
       "      <td>-38.0</td>\n",
       "      <td>-156.285714</td>\n",
       "      <td>-1094.0</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307503</th>\n",
       "      <td>456252</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>72000.0</td>\n",
       "      <td>269550.0</td>\n",
       "      <td>12001.5</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10069.867500</td>\n",
       "      <td>60419.205</td>\n",
       "      <td>10046.880</td>\n",
       "      <td>10074.465</td>\n",
       "      <td>10069.867500</td>\n",
       "      <td>60419.205</td>\n",
       "      <td>-2327.0</td>\n",
       "      <td>-2393.833333</td>\n",
       "      <td>-14363.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307504</th>\n",
       "      <td>456253</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>153000.0</td>\n",
       "      <td>677664.0</td>\n",
       "      <td>29979.0</td>\n",
       "      <td>585000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4399.707857</td>\n",
       "      <td>61595.910</td>\n",
       "      <td>27.270</td>\n",
       "      <td>5575.185</td>\n",
       "      <td>4115.915357</td>\n",
       "      <td>57622.815</td>\n",
       "      <td>-1738.0</td>\n",
       "      <td>-2387.428571</td>\n",
       "      <td>-33424.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307505</th>\n",
       "      <td>456254</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>171000.0</td>\n",
       "      <td>370107.0</td>\n",
       "      <td>20205.0</td>\n",
       "      <td>319500.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10239.832895</td>\n",
       "      <td>194556.825</td>\n",
       "      <td>2296.440</td>\n",
       "      <td>19065.825</td>\n",
       "      <td>10239.832895</td>\n",
       "      <td>194556.825</td>\n",
       "      <td>-18.0</td>\n",
       "      <td>-161.263158</td>\n",
       "      <td>-3064.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307506</th>\n",
       "      <td>456255</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>49117.5</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>41464.713649</td>\n",
       "      <td>3068388.810</td>\n",
       "      <td>34.965</td>\n",
       "      <td>669251.655</td>\n",
       "      <td>47646.215878</td>\n",
       "      <td>3525819.975</td>\n",
       "      <td>-76.0</td>\n",
       "      <td>-472.013514</td>\n",
       "      <td>-34929.0</td>\n",
       "      <td>74.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>307507 rows × 626 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        SK_ID_CURR  TARGET  CODE_GENDER  FLAG_OWN_CAR  FLAG_OWN_REALTY  \\\n",
       "0           100002     1.0            0             0                0   \n",
       "1           100003     0.0            1             0                1   \n",
       "2           100004     0.0            0             1                0   \n",
       "3           100006     0.0            1             0                0   \n",
       "4           100007     0.0            0             0                0   \n",
       "...            ...     ...          ...           ...              ...   \n",
       "307502      456251     0.0            0             0                1   \n",
       "307503      456252     0.0            1             0                0   \n",
       "307504      456253     0.0            1             0                0   \n",
       "307505      456254     1.0            1             0                0   \n",
       "307506      456255     0.0            1             0                1   \n",
       "\n",
       "        CNT_CHILDREN  AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  \\\n",
       "0                  0          202500.0    406597.5      24700.5   \n",
       "1                  0          270000.0   1293502.5      35698.5   \n",
       "2                  0           67500.0    135000.0       6750.0   \n",
       "3                  0          135000.0    312682.5      29686.5   \n",
       "4                  0          121500.0    513000.0      21865.5   \n",
       "...              ...               ...         ...          ...   \n",
       "307502             0          157500.0    254700.0      27558.0   \n",
       "307503             0           72000.0    269550.0      12001.5   \n",
       "307504             0          153000.0    677664.0      29979.0   \n",
       "307505             0          171000.0    370107.0      20205.0   \n",
       "307506             0          157500.0    675000.0      49117.5   \n",
       "\n",
       "        AMT_GOODS_PRICE  ...  INSTAL_AMT_INSTALMENT_MEAN  \\\n",
       "0              351000.0  ...                11559.247105   \n",
       "1             1129500.0  ...                64754.586000   \n",
       "2              135000.0  ...                 7096.155000   \n",
       "3              297000.0  ...                62947.088438   \n",
       "4              513000.0  ...                12666.444545   \n",
       "...                 ...  ...                         ...   \n",
       "307502         225000.0  ...                 7492.924286   \n",
       "307503         225000.0  ...                10069.867500   \n",
       "307504         585000.0  ...                 4399.707857   \n",
       "307505         319500.0  ...                10239.832895   \n",
       "307506         675000.0  ...                41464.713649   \n",
       "\n",
       "        INSTAL_AMT_INSTALMENT_SUM  INSTAL_AMT_PAYMENT_MIN  \\\n",
       "0                      219625.695                9251.775   \n",
       "1                     1618864.650                6662.970   \n",
       "2                       21288.465                5357.250   \n",
       "3                     1007153.415                2482.920   \n",
       "4                      835985.340                   0.180   \n",
       "...                           ...                     ...   \n",
       "307502                  52450.470                6605.910   \n",
       "307503                  60419.205               10046.880   \n",
       "307504                  61595.910                  27.270   \n",
       "307505                 194556.825                2296.440   \n",
       "307506                3068388.810                  34.965   \n",
       "\n",
       "        INSTAL_AMT_PAYMENT_MAX  INSTAL_AMT_PAYMENT_MEAN  \\\n",
       "0                    53093.745             11559.247105   \n",
       "1                   560835.360             64754.586000   \n",
       "2                    10573.965              7096.155000   \n",
       "3                   691786.890             62947.088438   \n",
       "4                    22678.785             12214.060227   \n",
       "...                        ...                      ...   \n",
       "307502               12815.010              7492.924286   \n",
       "307503               10074.465             10069.867500   \n",
       "307504                5575.185              4115.915357   \n",
       "307505               19065.825             10239.832895   \n",
       "307506              669251.655             47646.215878   \n",
       "\n",
       "        INSTAL_AMT_PAYMENT_SUM  INSTAL_DAYS_ENTRY_PAYMENT_MAX  \\\n",
       "0                   219625.695                          -49.0   \n",
       "1                  1618864.650                         -544.0   \n",
       "2                    21288.465                         -727.0   \n",
       "3                  1007153.415                          -12.0   \n",
       "4                   806127.975                          -14.0   \n",
       "...                        ...                            ...   \n",
       "307502               52450.470                          -38.0   \n",
       "307503               60419.205                        -2327.0   \n",
       "307504               57622.815                        -1738.0   \n",
       "307505              194556.825                          -18.0   \n",
       "307506             3525819.975                          -76.0   \n",
       "\n",
       "        INSTAL_DAYS_ENTRY_PAYMENT_MEAN  INSTAL_DAYS_ENTRY_PAYMENT_SUM  \\\n",
       "0                          -315.421053                        -5993.0   \n",
       "1                         -1385.320000                       -34633.0   \n",
       "2                          -761.666667                        -2285.0   \n",
       "3                          -271.625000                        -4346.0   \n",
       "4                         -1032.242424                       -68128.0   \n",
       "...                                ...                            ...   \n",
       "307502                     -156.285714                        -1094.0   \n",
       "307503                    -2393.833333                       -14363.0   \n",
       "307504                    -2387.428571                       -33424.0   \n",
       "307505                     -161.263158                        -3064.0   \n",
       "307506                     -472.013514                       -34929.0   \n",
       "\n",
       "        INSTAL_COUNT  \n",
       "0               19.0  \n",
       "1               25.0  \n",
       "2                3.0  \n",
       "3               16.0  \n",
       "4               66.0  \n",
       "...              ...  \n",
       "307502           7.0  \n",
       "307503           6.0  \n",
       "307504          14.0  \n",
       "307505          19.0  \n",
       "307506          74.0  \n",
       "\n",
       "[307507 rows x 626 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv('df_clean_imputed.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de NaN par colonne :\n",
      " SK_ID_CURR                        0\n",
      "TARGET                            0\n",
      "CODE_GENDER                       0\n",
      "FLAG_OWN_CAR                      0\n",
      "FLAG_OWN_REALTY                   0\n",
      "                                 ..\n",
      "INSTAL_AMT_PAYMENT_SUM            0\n",
      "INSTAL_DAYS_ENTRY_PAYMENT_MAX     0\n",
      "INSTAL_DAYS_ENTRY_PAYMENT_MEAN    0\n",
      "INSTAL_DAYS_ENTRY_PAYMENT_SUM     0\n",
      "INSTAL_COUNT                      0\n",
      "Length: 626, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Afficher le nombre de NaN par colonne\n",
    "nan_counts = df.isna().sum()\n",
    "print(\"Nombre de NaN par colonne :\\n\", nan_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille du jeu d'entraînement : (304431, 626)\n",
      "Taille du jeu de test : (3076, 626)\n"
     ]
    }
   ],
   "source": [
    "#division initiale des données : 99% pour train (train_initial et final) et 1% pour X_nouveaux_clients (test)\n",
    "#un sample sera pris des 90% pour la recherche des hyperparametres\n",
    "#le model final sera entrainé sur toutes les données le 100% des 90%\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Séparer 1% des données pour le test en utilisant la stratification\n",
    "df_train, df_test = train_test_split(\n",
    "    df, \n",
    "    test_size=0.01, \n",
    "    random_state=42, \n",
    "    stratify=df['TARGET']\n",
    ")\n",
    "\n",
    "# Vérification des dimensions des jeux de données\n",
    "print(f\"Taille du jeu d'entraînement : {df_train.shape}\")\n",
    "print(f\"Taille du jeu de test : {df_test.shape}\")\n",
    "\n",
    "#df_train.to_csv('df_train_i.csv', index=False)\n",
    "#df_test.to_csv('df_test_i.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de X_train_eval: (30443, 625)\n",
      "Taille de y_train_eval: (30443,)\n",
      "Taille de X_api: (3076, 625)\n",
      "Taille de y_api: (3076,)\n",
      "Taille de X_final: (304431, 625)\n",
      "Taille de y_final: (304431,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#pour le df_test\n",
    "\n",
    "# Séparer les features (X) et la cible (y)\n",
    "X_api = df_test.drop(columns=['TARGET'])  \n",
    "y_api = df_test['TARGET']\n",
    "\n",
    "#pour df_train\n",
    "\n",
    "# Séparation de 10% de df_train pour la recherche d'hyperparamètres\n",
    "df_train_eval, df_unused = train_test_split(df_train, test_size=0.9, stratify=df_train['TARGET'], random_state=42)\n",
    "\n",
    "# Séparation des caractéristiques (X) et de la cible (y)\n",
    "X_train_eval = df_train_eval.drop(columns='TARGET')\n",
    "y_train_eval = df_train_eval['TARGET']\n",
    "X_final = df_train.drop(columns='TARGET')\n",
    "y_final = df_train['TARGET']\n",
    "\n",
    "# Vérification des dimensions pour confirmation\n",
    "print(\"Taille de X_train_eval:\", X_train_eval.shape)\n",
    "print(\"Taille de y_train_eval:\", y_train_eval.shape)\n",
    "print(\"Taille de X_api:\", X_api.shape)\n",
    "print(\"Taille de y_api:\", y_api.shape)\n",
    "print(\"Taille de X_final:\", X_final.shape)\n",
    "print(\"Taille de y_final:\", y_final.shape)\n",
    "\n",
    "# X_train_eval et y_train_eval : Utilisés pour l'entraînement et la validation des modèles\n",
    "# X_api et y_api : Échantillon pour tester l'API\n",
    "# X_final et y_final : Jeu de données final pour évaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Réinitialiser les index pour s'assurer qu'ils sont consécutifs\n",
    "X_train_eval = X_train_eval.reset_index(drop=True)\n",
    "y_train_eval = y_train_eval.reset_index(drop=True)\n",
    "X_final = X_final.reset_index(drop=True)\n",
    "y_final = y_final.reset_index(drop=True)\n",
    "X_api = X_api.reset_index(drop=True)\n",
    "y_api = y_api.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_eval = X_train_eval.to_csv('X_train_eval.csv', index=False)\n",
    "y_train_eval = y_train_eval.to_csv('y_train_eval.csv', index=False)\n",
    "X_final = X_final.to_csv('X_final.csv', index=False)\n",
    "y_final = y_final.to_csv('y_final.csv', index=False)\n",
    "X_api = X_api.to_csv('X_api.csv', index=False)\n",
    "y_api = y_api.to_csv('y_api.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>CODE_GENDER</th>\n",
       "      <th>FLAG_OWN_CAR</th>\n",
       "      <th>FLAG_OWN_REALTY</th>\n",
       "      <th>CNT_CHILDREN</th>\n",
       "      <th>AMT_INCOME_TOTAL</th>\n",
       "      <th>AMT_CREDIT</th>\n",
       "      <th>AMT_ANNUITY</th>\n",
       "      <th>AMT_GOODS_PRICE</th>\n",
       "      <th>REGION_POPULATION_RELATIVE</th>\n",
       "      <th>...</th>\n",
       "      <th>INSTAL_AMT_INSTALMENT_MEAN</th>\n",
       "      <th>INSTAL_AMT_INSTALMENT_SUM</th>\n",
       "      <th>INSTAL_AMT_PAYMENT_MIN</th>\n",
       "      <th>INSTAL_AMT_PAYMENT_MAX</th>\n",
       "      <th>INSTAL_AMT_PAYMENT_MEAN</th>\n",
       "      <th>INSTAL_AMT_PAYMENT_SUM</th>\n",
       "      <th>INSTAL_DAYS_ENTRY_PAYMENT_MAX</th>\n",
       "      <th>INSTAL_DAYS_ENTRY_PAYMENT_MEAN</th>\n",
       "      <th>INSTAL_DAYS_ENTRY_PAYMENT_SUM</th>\n",
       "      <th>INSTAL_COUNT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>128587.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>90000.0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>26833.5</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>0.014520</td>\n",
       "      <td>...</td>\n",
       "      <td>26205.082031</td>\n",
       "      <td>3.668711e+05</td>\n",
       "      <td>6355.620117</td>\n",
       "      <td>283500.000000</td>\n",
       "      <td>46455.082031</td>\n",
       "      <td>6.503711e+05</td>\n",
       "      <td>-63.000000</td>\n",
       "      <td>-221.285721</td>\n",
       "      <td>-3098.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>372756.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>112500.0</td>\n",
       "      <td>152820.0</td>\n",
       "      <td>15016.5</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>0.007330</td>\n",
       "      <td>...</td>\n",
       "      <td>15361.418945</td>\n",
       "      <td>3.379512e+05</td>\n",
       "      <td>3760.110107</td>\n",
       "      <td>90001.031250</td>\n",
       "      <td>19452.375000</td>\n",
       "      <td>4.279522e+05</td>\n",
       "      <td>-500.000000</td>\n",
       "      <td>-988.409119</td>\n",
       "      <td>-21745.000000</td>\n",
       "      <td>22.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>145763.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>630000.0</td>\n",
       "      <td>42102.0</td>\n",
       "      <td>630000.0</td>\n",
       "      <td>0.010006</td>\n",
       "      <td>...</td>\n",
       "      <td>32705.423828</td>\n",
       "      <td>1.635271e+05</td>\n",
       "      <td>16181.955078</td>\n",
       "      <td>98799.296875</td>\n",
       "      <td>32705.423828</td>\n",
       "      <td>1.635271e+05</td>\n",
       "      <td>-429.000000</td>\n",
       "      <td>-486.000000</td>\n",
       "      <td>-2430.000000</td>\n",
       "      <td>5.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140115.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>157500.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>9000.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>0.019689</td>\n",
       "      <td>...</td>\n",
       "      <td>4864.249512</td>\n",
       "      <td>1.118777e+05</td>\n",
       "      <td>66.735001</td>\n",
       "      <td>6912.000000</td>\n",
       "      <td>4721.176758</td>\n",
       "      <td>1.085871e+05</td>\n",
       "      <td>-158.000000</td>\n",
       "      <td>-457.869568</td>\n",
       "      <td>-10531.000000</td>\n",
       "      <td>23.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>323149.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81000.0</td>\n",
       "      <td>239850.0</td>\n",
       "      <td>23494.5</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>0.009334</td>\n",
       "      <td>...</td>\n",
       "      <td>19393.498047</td>\n",
       "      <td>1.570873e+06</td>\n",
       "      <td>12303.000000</td>\n",
       "      <td>26305.964844</td>\n",
       "      <td>19393.498047</td>\n",
       "      <td>1.570873e+06</td>\n",
       "      <td>-226.000000</td>\n",
       "      <td>-1667.555542</td>\n",
       "      <td>-135072.000000</td>\n",
       "      <td>81.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3071</th>\n",
       "      <td>203011.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>180000.0</td>\n",
       "      <td>755190.0</td>\n",
       "      <td>36459.0</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>0.010032</td>\n",
       "      <td>...</td>\n",
       "      <td>31136.744141</td>\n",
       "      <td>1.868205e+05</td>\n",
       "      <td>19008.000000</td>\n",
       "      <td>91780.468750</td>\n",
       "      <td>31136.744141</td>\n",
       "      <td>1.868205e+05</td>\n",
       "      <td>-407.000000</td>\n",
       "      <td>-492.833344</td>\n",
       "      <td>-2957.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3072</th>\n",
       "      <td>450657.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>202500.0</td>\n",
       "      <td>545040.0</td>\n",
       "      <td>36553.5</td>\n",
       "      <td>450000.0</td>\n",
       "      <td>0.020246</td>\n",
       "      <td>...</td>\n",
       "      <td>21627.634766</td>\n",
       "      <td>1.038126e+06</td>\n",
       "      <td>9053.325195</td>\n",
       "      <td>105815.609375</td>\n",
       "      <td>22377.634766</td>\n",
       "      <td>1.074126e+06</td>\n",
       "      <td>-12.000000</td>\n",
       "      <td>-713.625000</td>\n",
       "      <td>-34254.000000</td>\n",
       "      <td>48.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3073</th>\n",
       "      <td>123757.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>225000.0</td>\n",
       "      <td>714915.0</td>\n",
       "      <td>28102.5</td>\n",
       "      <td>639000.0</td>\n",
       "      <td>0.011657</td>\n",
       "      <td>...</td>\n",
       "      <td>7965.629883</td>\n",
       "      <td>7.169067e+04</td>\n",
       "      <td>7965.629883</td>\n",
       "      <td>7965.629883</td>\n",
       "      <td>7965.629883</td>\n",
       "      <td>7.169067e+04</td>\n",
       "      <td>-27.000000</td>\n",
       "      <td>-148.000000</td>\n",
       "      <td>-1332.000000</td>\n",
       "      <td>9.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3074</th>\n",
       "      <td>286869.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>282073.5</td>\n",
       "      <td>3150000.0</td>\n",
       "      <td>79632.0</td>\n",
       "      <td>3150000.0</td>\n",
       "      <td>0.018850</td>\n",
       "      <td>...</td>\n",
       "      <td>18392.646484</td>\n",
       "      <td>6.724082e+05</td>\n",
       "      <td>5198.160645</td>\n",
       "      <td>138179.734375</td>\n",
       "      <td>18754.361328</td>\n",
       "      <td>6.785789e+05</td>\n",
       "      <td>-327.788391</td>\n",
       "      <td>-920.959961</td>\n",
       "      <td>-41719.511719</td>\n",
       "      <td>39.745552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3075</th>\n",
       "      <td>212482.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>135000.0</td>\n",
       "      <td>808650.0</td>\n",
       "      <td>21460.5</td>\n",
       "      <td>675000.0</td>\n",
       "      <td>0.019101</td>\n",
       "      <td>...</td>\n",
       "      <td>4667.229492</td>\n",
       "      <td>8.867736e+04</td>\n",
       "      <td>45.990002</td>\n",
       "      <td>4623.660156</td>\n",
       "      <td>2452.869385</td>\n",
       "      <td>4.660452e+04</td>\n",
       "      <td>-2644.000000</td>\n",
       "      <td>-2764.263184</td>\n",
       "      <td>-52521.000000</td>\n",
       "      <td>19.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3076 rows × 625 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      SK_ID_CURR  CODE_GENDER  FLAG_OWN_CAR  FLAG_OWN_REALTY  CNT_CHILDREN  \\\n",
       "0       128587.0          1.0           0.0              0.0           0.0   \n",
       "1       372756.0          1.0           0.0              0.0           1.0   \n",
       "2       145763.0          1.0           0.0              0.0           0.0   \n",
       "3       140115.0          1.0           0.0              0.0           1.0   \n",
       "4       323149.0          0.0           1.0              0.0           0.0   \n",
       "...          ...          ...           ...              ...           ...   \n",
       "3071    203011.0          0.0           1.0              0.0           0.0   \n",
       "3072    450657.0          0.0           0.0              1.0           0.0   \n",
       "3073    123757.0          0.0           1.0              0.0           0.0   \n",
       "3074    286869.0          0.0           1.0              1.0           0.0   \n",
       "3075    212482.0          1.0           0.0              1.0           1.0   \n",
       "\n",
       "      AMT_INCOME_TOTAL  AMT_CREDIT  AMT_ANNUITY  AMT_GOODS_PRICE  \\\n",
       "0              90000.0    225000.0      26833.5         225000.0   \n",
       "1             112500.0    152820.0      15016.5         135000.0   \n",
       "2             225000.0    630000.0      42102.0         630000.0   \n",
       "3             157500.0    180000.0       9000.0         180000.0   \n",
       "4              81000.0    239850.0      23494.5         225000.0   \n",
       "...                ...         ...          ...              ...   \n",
       "3071          180000.0    755190.0      36459.0         675000.0   \n",
       "3072          202500.0    545040.0      36553.5         450000.0   \n",
       "3073          225000.0    714915.0      28102.5         639000.0   \n",
       "3074          282073.5   3150000.0      79632.0        3150000.0   \n",
       "3075          135000.0    808650.0      21460.5         675000.0   \n",
       "\n",
       "      REGION_POPULATION_RELATIVE  ...  INSTAL_AMT_INSTALMENT_MEAN  \\\n",
       "0                       0.014520  ...                26205.082031   \n",
       "1                       0.007330  ...                15361.418945   \n",
       "2                       0.010006  ...                32705.423828   \n",
       "3                       0.019689  ...                 4864.249512   \n",
       "4                       0.009334  ...                19393.498047   \n",
       "...                          ...  ...                         ...   \n",
       "3071                    0.010032  ...                31136.744141   \n",
       "3072                    0.020246  ...                21627.634766   \n",
       "3073                    0.011657  ...                 7965.629883   \n",
       "3074                    0.018850  ...                18392.646484   \n",
       "3075                    0.019101  ...                 4667.229492   \n",
       "\n",
       "      INSTAL_AMT_INSTALMENT_SUM  INSTAL_AMT_PAYMENT_MIN  \\\n",
       "0                  3.668711e+05             6355.620117   \n",
       "1                  3.379512e+05             3760.110107   \n",
       "2                  1.635271e+05            16181.955078   \n",
       "3                  1.118777e+05               66.735001   \n",
       "4                  1.570873e+06            12303.000000   \n",
       "...                         ...                     ...   \n",
       "3071               1.868205e+05            19008.000000   \n",
       "3072               1.038126e+06             9053.325195   \n",
       "3073               7.169067e+04             7965.629883   \n",
       "3074               6.724082e+05             5198.160645   \n",
       "3075               8.867736e+04               45.990002   \n",
       "\n",
       "      INSTAL_AMT_PAYMENT_MAX  INSTAL_AMT_PAYMENT_MEAN  INSTAL_AMT_PAYMENT_SUM  \\\n",
       "0              283500.000000             46455.082031            6.503711e+05   \n",
       "1               90001.031250             19452.375000            4.279522e+05   \n",
       "2               98799.296875             32705.423828            1.635271e+05   \n",
       "3                6912.000000              4721.176758            1.085871e+05   \n",
       "4               26305.964844             19393.498047            1.570873e+06   \n",
       "...                      ...                      ...                     ...   \n",
       "3071            91780.468750             31136.744141            1.868205e+05   \n",
       "3072           105815.609375             22377.634766            1.074126e+06   \n",
       "3073             7965.629883              7965.629883            7.169067e+04   \n",
       "3074           138179.734375             18754.361328            6.785789e+05   \n",
       "3075             4623.660156              2452.869385            4.660452e+04   \n",
       "\n",
       "      INSTAL_DAYS_ENTRY_PAYMENT_MAX  INSTAL_DAYS_ENTRY_PAYMENT_MEAN  \\\n",
       "0                        -63.000000                     -221.285721   \n",
       "1                       -500.000000                     -988.409119   \n",
       "2                       -429.000000                     -486.000000   \n",
       "3                       -158.000000                     -457.869568   \n",
       "4                       -226.000000                    -1667.555542   \n",
       "...                             ...                             ...   \n",
       "3071                    -407.000000                     -492.833344   \n",
       "3072                     -12.000000                     -713.625000   \n",
       "3073                     -27.000000                     -148.000000   \n",
       "3074                    -327.788391                     -920.959961   \n",
       "3075                   -2644.000000                    -2764.263184   \n",
       "\n",
       "      INSTAL_DAYS_ENTRY_PAYMENT_SUM  INSTAL_COUNT  \n",
       "0                      -3098.000000     14.000000  \n",
       "1                     -21745.000000     22.000000  \n",
       "2                      -2430.000000      5.000000  \n",
       "3                     -10531.000000     23.000000  \n",
       "4                    -135072.000000     81.000000  \n",
       "...                             ...           ...  \n",
       "3071                   -2957.000000      6.000000  \n",
       "3072                  -34254.000000     48.000000  \n",
       "3073                   -1332.000000      9.000000  \n",
       "3074                  -41719.511719     39.745552  \n",
       "3075                  -52521.000000     19.000000  \n",
       "\n",
       "[3076 rows x 625 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#les nouveaux client pour l'api en float32\n",
    "import numpy as np\n",
    "\n",
    "# Convertir X_api \n",
    "X_api = X_api.astype(np.float32)\n",
    "#X_api.to_csv('df_clients.csv', index=False)\n",
    "X_api"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Dummy Classifier avec smote et scaler et imputation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 973.90it/s]\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 919.17it/s] \n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<?, ?it/s]\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<?, ?it/s]\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 354.33it/s]\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<?, ?it/s]\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<?, ?it/s]\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 422.89it/s]\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<?, ?it/s]\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<?, ?it/s]\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 315.65it/s]\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 575.91it/s]\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 419.01it/s]\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<00:00, 415.37it/s]\n",
      "Downloading artifacts: 100%|██████████| 7/7 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'entraînement total: 222.84 secondes\n",
      "{'strategy': 'most_frequent'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['best_params_dc.pkl']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#1\n",
    "import time\n",
    "import logging\n",
    "import gc\n",
    "import mlflow\n",
    "import optuna\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, roc_curve\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Initialisation\n",
    "smote = SMOTE(random_state=42)\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "results_dc = []\n",
    "nb_runs = 15\n",
    "logging.getLogger('optuna').setLevel(logging.CRITICAL)\n",
    "\n",
    "# Chronomètre d'entraînement\n",
    "start_time = time.time()\n",
    "\n",
    "# Définir l'expérience MLflow\n",
    "mlflow.set_experiment('Dummy Classifier')\n",
    "\n",
    "# Chargement des fichiers  :\n",
    "X_train_eval = pd.read_csv('X_train_eval.csv')\n",
    "y_train_eval = pd.read_csv('y_train_eval.csv')\n",
    "X_final = pd.read_csv('X_final.csv')\n",
    "y_final = pd.read_csv('y_final.csv')\n",
    "X_api = pd.read_csv('X_api.csv')\n",
    "y_api = pd.read_csv('y_api.csv')\n",
    "\n",
    "# Standardisation des données\n",
    "scaler_dc = StandardScaler()\n",
    "\n",
    "# Applique la transformation sur les données d'entraînement et de test avec la conversion en float32 pour économiser la mémoire\n",
    "X_train_eval_scaled = scaler_dc.fit_transform(X_train_eval).astype(np.float32)\n",
    "X_final_scaled = scaler_dc.transform(X_final).astype(np.float32)\n",
    "\n",
    "# Sauvegarde du scaler pour réutilisation ultérieure\n",
    "joblib.dump(scaler_dc, 'scaler_dc.joblib')\n",
    "\n",
    "# Conversion en float32 pour économiser la mémoire\n",
    "X_api=X_api.astype(np.float32)\n",
    "\n",
    "# Fonction de DummyClassifier pour l'optimisation Optuna\n",
    "def dummy_c(trial):\n",
    "    strategy = trial.suggest_categorical('strategy', ['stratified', 'most_frequent', 'prior', 'uniform', 'constant'])\n",
    "    # Vérifiez si la stratégie est \"constant\" et définissez une valeur de constante\n",
    "    if strategy == \"constant\":\n",
    "        constant_value = trial.suggest_categorical('constant_value', [0, 1])\n",
    "        model = DummyClassifier(strategy=strategy, constant=constant_value, random_state=42)\n",
    "    else:\n",
    "\n",
    "        # Création du modèle DummyClassifier\n",
    "        model = DummyClassifier(strategy=strategy, random_state=42)\n",
    "\n",
    "    auc_scores, acc_scores, cost_scores = [], [], []\n",
    "\n",
    "    # Validation croisée avec suréchantillonnage SMOTE\n",
    "    for train_idx, test_idx in cv.split(X_train_eval_scaled, y_train_eval):\n",
    "        #X_train, X_test = X_train_eval_scaled.iloc[train_idx], X_train_eval_scaled.iloc[test_idx]\n",
    "        #y_train, y_test = y_train_eval.iloc[train_idx], y_train_eval.iloc[test_idx]\n",
    "\n",
    "        X_train, X_test = X_train_eval_scaled[train_idx], X_train_eval_scaled[test_idx]\n",
    "        y_train, y_test = y_train_eval.iloc[train_idx].values, y_train_eval.iloc[test_idx].values\n",
    "\n",
    "        \n",
    "        # Appliquer SMOTE\n",
    "        X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "        model.fit(X_train_smote, y_train_smote)\n",
    "        \n",
    "        # Prédictions et probabilités\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "        y_pred = y_prob > 0.5\n",
    "\n",
    "        # Calcul des métriques\n",
    "        auc_scores.append(roc_auc_score(y_test, y_prob))\n",
    "        acc_scores.append(accuracy_score(y_test, y_pred))\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        cost_scores.append(fp + 10 * fn)\n",
    "\n",
    "    # Calcul des moyennes pour chaque métrique\n",
    "    auc = np.mean(auc_scores)\n",
    "    acc = np.mean(acc_scores)\n",
    "    cost = np.mean(cost_scores)\n",
    "\n",
    "    # Sauvegarde des résultats\n",
    "    results_dc.append({\"AUC\": auc, \"Accuracy\": acc, \"Business Score\": cost, \"Strategy\": strategy})\n",
    "\n",
    "    # Enregistrement dans MLflow\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_params(trial.params)\n",
    "        mlflow.log_metrics({\"AUC\": auc, \"Accuracy\": acc, \"Business Score\": cost})\n",
    "\n",
    "        # Courbe ROC\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        plt.plot(fpr, tpr, label=f'AUC: {auc:.2f}')\n",
    "        plt.title('ROC Curve')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.savefig(\"roc_curve_dc.png\")\n",
    "        plt.close()\n",
    "        mlflow.log_artifact(\"roc_curve_dc.png\")\n",
    "\n",
    "        mlflow.sklearn.log_model(model, \"dummy_classifier_model\", input_example=X_train_eval_scaled[:5])\n",
    "\n",
    "    gc.collect()\n",
    "    return cost\n",
    "\n",
    "# Optimisation avec Optuna\n",
    "study_dc = optuna.create_study(direction='minimize')\n",
    "study_dc.optimize(dummy_c, n_trials=nb_runs)\n",
    "\n",
    "# Fin du temps d'entraînement\n",
    "end_time = time.time()\n",
    "print(f\"Temps d'entraînement total: {end_time - start_time:.2f} secondes\")\n",
    "\n",
    "# Meilleurs résultats et paramètres\n",
    "best_params_dc = study_dc.best_params\n",
    "best_auc_dc = max([res['AUC'] for res in results_dc])\n",
    "best_acc_dc = max([res['Accuracy'] for res in results_dc])\n",
    "best_cost_dc = min([res['Business Score'] for res in results_dc])\n",
    "\n",
    "# Affichage des meilleurs paramètres\n",
    "print(study_dc.best_params)\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_params(best_params_dc)\n",
    "joblib.dump(best_params_dc, 'best_params_dc.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Temps d'entraînement final: 45.52 secondes\n",
      "Les résultats ont été exportés dans 'results_dummy_classifier.csv'\n"
     ]
    }
   ],
   "source": [
    "######################################################################################################################################################\n",
    "\n",
    "#2\n",
    "# Entraînement final sur toutes les données avec les meilleurs paramètres\n",
    "start_time = time.time()\n",
    "\n",
    "# Initialisation du modèle DummyClassifier avec les meilleurs paramètres obtenus\n",
    "final_model_dc = DummyClassifier(**best_params_dc, random_state=42)\n",
    "\n",
    "# Appliquer SMOTE sur toutes les données d'entraînement\n",
    "X_train_final_smote_dc, y_train_final_smote_dc = smote.fit_resample(X_final_scaled, y_final)\n",
    "\n",
    "# Entraînement du modèle final\n",
    "final_model_dc.fit(X_train_final_smote_dc, y_train_final_smote_dc)\n",
    "\n",
    "# Affichage du temps d'entraînement final\n",
    "end_time = time.time()\n",
    "print(f\"Temps d'entraînement final: {end_time - start_time:.2f} secondes\")\n",
    "\n",
    "# Enregistrement du modèle final\n",
    "joblib.dump(final_model_dc, 'dummy_classifier_model_f.joblib')\n",
    "\n",
    "# Sauvegarde des résultats dans un DataFrame\n",
    "results_df_dc = pd.DataFrame(results_dc)\n",
    "\n",
    "# Tri des résultats par Business Score croissant (du plus petit au plus grand)\n",
    "results_df_sorted_dc = results_df_dc.sort_values(by='Business Score', ascending=True)\n",
    "\n",
    "# Enregistrement des résultats dans un fichier CSV\n",
    "results_df_sorted_dc.to_csv('results_dummy_classifier.csv', index=False)\n",
    "\n",
    "print(\"Les résultats ont été exportés dans 'results_dummy_classifier.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métriques du modèle dummy_classifier final avec les meilleurs paramètres:\n",
      "AUC: 0.5000\n",
      "Accuracy: 0.9193\n",
      "Business Score: 245770.0000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SK_ID_CURR</th>\n",
       "      <th>Probabilité</th>\n",
       "      <th>Prédiction</th>\n",
       "      <th>Vrai_Label</th>\n",
       "      <th>AUC</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Business Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>202883</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.919269</td>\n",
       "      <td>245770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>353282</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.919269</td>\n",
       "      <td>245770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>280134</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.919269</td>\n",
       "      <td>245770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>111527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.919269</td>\n",
       "      <td>245770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>362418</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.919269</td>\n",
       "      <td>245770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>106400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.919269</td>\n",
       "      <td>245770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>103241</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.919269</td>\n",
       "      <td>245770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>228257</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.919269</td>\n",
       "      <td>245770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>179577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.919269</td>\n",
       "      <td>245770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>245931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.919269</td>\n",
       "      <td>245770</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   SK_ID_CURR  Probabilité  Prédiction  Vrai_Label  AUC  Accuracy  \\\n",
       "0      202883          0.0       False         0.0  0.5  0.919269   \n",
       "1      353282          0.0       False         0.0  0.5  0.919269   \n",
       "2      280134          0.0       False         0.0  0.5  0.919269   \n",
       "3      111527          0.0       False         0.0  0.5  0.919269   \n",
       "4      362418          0.0       False         0.0  0.5  0.919269   \n",
       "5      106400          0.0       False         0.0  0.5  0.919269   \n",
       "6      103241          0.0       False         0.0  0.5  0.919269   \n",
       "7      228257          0.0       False         1.0  0.5  0.919269   \n",
       "8      179577          0.0       False         0.0  0.5  0.919269   \n",
       "9      245931          0.0       False         0.0  0.5  0.919269   \n",
       "\n",
       "   Business Score  \n",
       "0          245770  \n",
       "1          245770  \n",
       "2          245770  \n",
       "3          245770  \n",
       "4          245770  \n",
       "5          245770  \n",
       "6          245770  \n",
       "7          245770  \n",
       "8          245770  \n",
       "9          245770  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "######################################################################################################################################################\n",
    "\n",
    "#3\n",
    "# Aplatir y_final pour le rendre compatible avec les autres colonnes 1D\n",
    "y_final = y_final.values.flatten() \n",
    "\n",
    "# Prédictions finales et métriques\n",
    "y_prob_final_dc = final_model_dc.predict_proba(X_final_scaled)[:, 1]\n",
    "y_pred_final_dc = y_prob_final_dc > 0.5\n",
    "\n",
    "# Calcul des métriques finales en utilisant y_final\n",
    "final_auc = roc_auc_score(y_final, y_prob_final_dc)\n",
    "final_accuracy = accuracy_score(y_final, y_pred_final_dc)\n",
    "tn, fp, fn, tp = confusion_matrix(y_final, y_pred_final_dc).ravel()\n",
    "final_cost = fp + 10 * fn\n",
    "\n",
    "# Création du DataFrame avec les métriques pour chaque client\n",
    "results_df_dc_f = pd.DataFrame({\n",
    "    \"SK_ID_CURR\": X_final['SK_ID_CURR'].values,  \n",
    "    \"Probabilité\": y_prob_final_dc,\n",
    "    \"Prédiction\": y_pred_final_dc,\n",
    "    \"Vrai_Label\": y_final\n",
    "})\n",
    "\n",
    "# Ajout des métriques globales en tant que nouvelles colonnes\n",
    "results_df_dc_f[\"AUC\"] = final_auc  # Ajoute AUC global, qui est la même pour tous\n",
    "results_df_dc_f[\"Accuracy\"] = final_accuracy  # Ajoute Accuracy global, qui est la même pour tous\n",
    "results_df_dc_f[\"Business Score\"] = final_cost  # Ajoute Business Score global, qui est la même pour tous\n",
    "\n",
    "print(\"Métriques du modèle dummy_classifier final avec les meilleurs paramètres:\")\n",
    "print(f\"AUC: {final_auc:.4f}\")\n",
    "print(f\"Accuracy: {final_accuracy:.4f}\")\n",
    "print(f\"Business Score: {final_cost:.4f}\")\n",
    "\n",
    "# Affichage du DataFrame final\n",
    "results_df_dc_f.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Métriques du modèle dummy_classifier final avec les meilleurs paramètres sur les données test:\n",
      "AUC: 0.5000\n",
      "Accuracy: 0.9194\n",
      "Business Score: 2480.0000\n"
     ]
    }
   ],
   "source": [
    "######################################################################################################################################################\n",
    "\n",
    "#4\n",
    "X_api_scaled = scaler_dc.transform(X_api).astype(np.float32)\n",
    "\n",
    "# Prédictions finales et métriques\n",
    "y_prob_final_dc = final_model_dc.predict_proba(X_api_scaled)[:, 1]\n",
    "y_pred_final_dc = y_prob_final_dc > 0.5\n",
    "\n",
    "# Calcul des métriques finales\n",
    "final_auc = roc_auc_score(y_api, y_prob_final_dc)\n",
    "final_accuracy = accuracy_score(y_api, y_pred_final_dc)\n",
    "tn, fp, fn, tp = confusion_matrix(y_api, y_pred_final_dc).ravel()\n",
    "final_cost = fp + 10 * fn  \n",
    "\n",
    "print(\"Métriques du modèle dummy_classifier final avec les meilleurs paramètres sur les données test:\")\n",
    "print(f\"AUC: {final_auc:.4f}\")\n",
    "print(f\"Accuracy: {final_accuracy:.4f}\")\n",
    "print(f\"Business Score: {final_cost:.4f}\")\n",
    "\n",
    "# Enregistrement des métriques finales dans MLflow\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_metrics({\"Final AUC_t dummy_classifier\": final_auc, \"Final Accuracy_t dummy_classifier\": final_accuracy, \"Final Business Score_t dummy_classifier\": final_cost}) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''#1\n",
    "import time\n",
    "import logging\n",
    "import gc\n",
    "import mlflow\n",
    "import optuna\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, roc_curve\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "# Initialisation\n",
    "smote = SMOTE(random_state=42)\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "results_dc = []\n",
    "nb_runs = 15\n",
    "logging.getLogger('optuna').setLevel(logging.CRITICAL)\n",
    "\n",
    "# Chronomètre d'entraînement\n",
    "start_time = time.time()\n",
    "\n",
    "# Définir l'expérience MLflow\n",
    "mlflow.set_experiment('Dummy Classifier')\n",
    "\n",
    "# Standardisation des données\n",
    "scaler_dc = StandardScaler()\n",
    "\n",
    "# Applique la transformation sur les données d'entraînement et de test avec la conversion en float32 pour économiser la mémoire\n",
    "X_train_eval_scaled = scaler_dc.fit_transform(X_train_eval).astype(np.float32)\n",
    "X_final_scaled = scaler_dc.transform(X_final).astype(np.float32)\n",
    "\n",
    "# Sauvegarde du scaler pour réutilisation ultérieure\n",
    "joblib.dump(scaler_dc, 'scaler_dc.joblib')\n",
    "\n",
    "# Conversion en float32 pour économiser la mémoire\n",
    "X_api=X_api.astype(np.float32)\n",
    "\n",
    "# Fonction de DummyClassifier pour l'optimisation Optuna\n",
    "def dummy_c(trial):\n",
    "    strategy = trial.suggest_categorical('strategy', ['stratified', 'most_frequent', 'prior', 'uniform', 'constant'])\n",
    "    # Vérifiez si la stratégie est \"constant\" et définissez une valeur de constante\n",
    "    if strategy == \"constant\":\n",
    "        constant_value = trial.suggest_categorical('constant_value', [0, 1])\n",
    "        model = DummyClassifier(strategy=strategy, constant=constant_value, random_state=42)\n",
    "    else:\n",
    "\n",
    "        # Création du modèle DummyClassifier\n",
    "        model = DummyClassifier(strategy=strategy, random_state=42)\n",
    "\n",
    "    auc_scores, acc_scores, cost_scores = [], [], []\n",
    "\n",
    "    # Validation croisée avec suréchantillonnage SMOTE\n",
    "    for train_idx, test_idx in cv.split(X_train_eval_scaled, y_train_eval):\n",
    "        #X_train, X_test = X_train_eval_scaled.iloc[train_idx], X_train_eval_scaled.iloc[test_idx]\n",
    "        #y_train, y_test = y_train_eval.iloc[train_idx], y_train_eval.iloc[test_idx]\n",
    "\n",
    "        X_train, X_test = X_train_eval_scaled[train_idx], X_train_eval_scaled[test_idx]\n",
    "        y_train, y_test = y_train_eval.iloc[train_idx].values, y_train_eval.iloc[test_idx].values\n",
    "\n",
    "        \n",
    "        # Appliquer SMOTE\n",
    "        X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "        model.fit(X_train_smote, y_train_smote)\n",
    "        \n",
    "        # Prédictions et probabilités\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "        y_pred = y_prob > 0.5\n",
    "\n",
    "        # Calcul des métriques\n",
    "        auc_scores.append(roc_auc_score(y_test, y_prob))\n",
    "        acc_scores.append(accuracy_score(y_test, y_pred))\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        cost_scores.append(fp + 10 * fn)\n",
    "\n",
    "    # Calcul des moyennes pour chaque métrique\n",
    "    auc = np.mean(auc_scores)\n",
    "    acc = np.mean(acc_scores)\n",
    "    cost = np.mean(cost_scores)\n",
    "\n",
    "    # Sauvegarde des résultats\n",
    "    results_dc.append({\"AUC\": auc, \"Accuracy\": acc, \"Business Score\": cost, \"Strategy\": strategy})\n",
    "\n",
    "    # Enregistrement dans MLflow\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_params(trial.params)\n",
    "        mlflow.log_metrics({\"AUC\": auc, \"Accuracy\": acc, \"Business Score\": cost})\n",
    "\n",
    "        # Courbe ROC\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        plt.plot(fpr, tpr, label=f'AUC: {auc:.2f}')\n",
    "        plt.title('ROC Curve')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.savefig(\"roc_curve_dc.png\")\n",
    "        plt.close()\n",
    "        mlflow.log_artifact(\"roc_curve_dc.png\")\n",
    "\n",
    "        mlflow.sklearn.log_model(model, \"dummy_classifier_model\", input_example=X_train_eval_scaled[:5])\n",
    "\n",
    "    gc.collect()\n",
    "    return cost\n",
    "\n",
    "# Optimisation avec Optuna\n",
    "study_dc = optuna.create_study(direction='minimize')\n",
    "study_dc.optimize(dummy_c, n_trials=nb_runs)\n",
    "\n",
    "# Fin du temps d'entraînement\n",
    "end_time = time.time()\n",
    "print(f\"Temps d'entraînement total: {end_time - start_time:.2f} secondes\")\n",
    "\n",
    "# Meilleurs résultats et paramètres\n",
    "best_params_dc = study_dc.best_params\n",
    "best_auc_dc = max([res['AUC'] for res in results_dc])\n",
    "best_acc_dc = max([res['Accuracy'] for res in results_dc])\n",
    "best_cost_dc = min([res['Business Score'] for res in results_dc])\n",
    "\n",
    "# Affichage des meilleurs paramètres\n",
    "print(study_dc.best_params)\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_params(best_params_dc)\n",
    "joblib.dump(best_params_dc, 'best_params_dc.pkl')\n",
    "\n",
    "######################################################################################################################################################\n",
    "\n",
    "#2\n",
    "# Entraînement final sur toutes les données avec les meilleurs paramètres\n",
    "start_time = time.time()\n",
    "\n",
    "# Initialisation du modèle DummyClassifier avec les meilleurs paramètres obtenus\n",
    "final_model_dc = DummyClassifier(**best_params_dc, random_state=42)\n",
    "\n",
    "# Appliquer SMOTE sur toutes les données d'entraînement\n",
    "X_train_final_smote_dc, y_train_final_smote_dc = smote.fit_resample(X_final_scaled, y_final)\n",
    "\n",
    "# Entraînement du modèle final\n",
    "final_model_dc.fit(X_train_final_smote_dc, y_train_final_smote_dc)\n",
    "\n",
    "# Affichage du temps d'entraînement final\n",
    "end_time = time.time()\n",
    "print(f\"Temps d'entraînement final: {end_time - start_time:.2f} secondes\")\n",
    "\n",
    "# Enregistrement du modèle final\n",
    "joblib.dump(final_model_dc, 'dummy_classifier_model_f.joblib')\n",
    "\n",
    "# Sauvegarde des résultats dans un DataFrame\n",
    "results_df_dc = pd.DataFrame(results_dc)\n",
    "\n",
    "# Tri des résultats par Business Score croissant (du plus petit au plus grand)\n",
    "results_df_sorted_dc = results_df_dc.sort_values(by='Business Score', ascending=True)\n",
    "\n",
    "# Enregistrement des résultats dans un fichier CSV\n",
    "results_df_sorted_dc.to_csv('results_dummy_classifier.csv', index=False)\n",
    "\n",
    "print(\"Les résultats ont été exportés dans 'results_dummy_classifier.csv'\")\n",
    "\n",
    "######################################################################################################################################################\n",
    "\n",
    "#3\n",
    "# Aplatir y_final pour le rendre compatible avec les autres colonnes 1D\n",
    "y_final = y_final.values.flatten()\n",
    "\n",
    "# Prédictions finales et métriques\n",
    "y_prob_final_dc = final_model_dc.predict_proba(X_final_scaled)[:, 1]\n",
    "y_pred_final_dc = y_prob_final_dc > 0.5\n",
    "\n",
    "# Calcul des métriques finales en utilisant y_final\n",
    "final_auc = roc_auc_score(y_final, y_prob_final_dc)\n",
    "final_accuracy = accuracy_score(y_final, y_pred_final_dc)\n",
    "tn, fp, fn, tp = confusion_matrix(y_final, y_pred_final_dc).ravel()\n",
    "final_cost = fp + 10 * fn\n",
    "\n",
    "# Création du DataFrame avec les métriques pour chaque client\n",
    "results_df_dc_f = pd.DataFrame({\n",
    "    \"SK_ID_CURR\": X_final['SK_ID_CURR'].values,  \n",
    "    \"Probabilité\": y_prob_final_dc,\n",
    "    \"Prédiction\": y_pred_final_dc,\n",
    "    \"Vrai_Label\": y_final\n",
    "})\n",
    "\n",
    "# Ajout des métriques globales en tant que nouvelles colonnes\n",
    "results_df_dc_f[\"AUC\"] = final_auc  # Ajoute AUC global, qui est la même pour tous\n",
    "results_df_dc_f[\"Accuracy\"] = final_accuracy  # Ajoute Accuracy global, qui est la même pour tous\n",
    "results_df_dc_f[\"Business Score\"] = final_cost  # Ajoute Business Score global, qui est la même pour tous\n",
    "\n",
    "print(\"Métriques du modèle dummy_classifier final avec les meilleurs paramètres:\")\n",
    "print(f\"AUC: {final_auc:.4f}\")\n",
    "print(f\"Accuracy: {final_accuracy:.4f}\")\n",
    "print(f\"Business Score: {final_cost:.4f}\")\n",
    "\n",
    "# Affichage du DataFrame final\n",
    "results_df_dc_f.head(10)\n",
    "\n",
    "######################################################################################################################################################\n",
    "\n",
    "#4\n",
    "X_api_scaled = scaler_dc.transform(X_api).astype(np.float32)\n",
    "\n",
    "# Prédictions finales et métriques\n",
    "y_prob_final_dc = final_model_dc.predict_proba(X_api_scaled)[:, 1]\n",
    "y_pred_final_dc = y_prob_final_dc > 0.5\n",
    "\n",
    "# Calcul des métriques finales\n",
    "final_auc = roc_auc_score(y_api, y_prob_final_dc)\n",
    "final_accuracy = accuracy_score(y_api, y_pred_final_dc)\n",
    "tn, fp, fn, tp = confusion_matrix(y_api, y_pred_final_dc).ravel()\n",
    "final_cost = fp + 10 * fn  \n",
    "\n",
    "print(\"Métriques du modèle dummy_classifier final avec les meilleurs paramètres sur les données test:\")\n",
    "print(f\"AUC: {final_auc:.4f}\")\n",
    "print(f\"Accuracy: {final_accuracy:.4f}\")\n",
    "print(f\"Business Score: {final_cost:.4f}\")\n",
    "\n",
    "# Enregistrement des métriques finales dans MLflow\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_metrics({\"Final AUC_t dummy_classifier\": final_auc, \"Final Accuracy_t dummy_classifier\": final_accuracy, \"Final Business Score_t dummy_classifier\": final_cost}) '''\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#logistic regression avec smote et scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "Exception",
     "evalue": "'C:\\Users\\HP\\OneDrive\\Documents\\projet7\\mlruns' does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[42], line 27\u001b[0m\n\u001b[0;32m     24\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[0;32m     26\u001b[0m \u001b[38;5;66;03m# Définir l'expérience MLflow\u001b[39;00m\n\u001b[1;32m---> 27\u001b[0m \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLogistic Regression Classifier\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;66;03m# Standardisation des données\u001b[39;00m\n\u001b[0;32m     30\u001b[0m scaler_lr \u001b[38;5;241m=\u001b[39m StandardScaler()\n",
      "File \u001b[1;32mc:\\Users\\HP\\OneDrive\\Documents\\projet7\\venv\\Lib\\site-packages\\mlflow\\tracking\\fluent.py:145\u001b[0m, in \u001b[0;36mset_experiment\u001b[1;34m(experiment_name, experiment_id)\u001b[0m\n\u001b[0;32m    143\u001b[0m client \u001b[38;5;241m=\u001b[39m MlflowClient()\n\u001b[0;32m    144\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m experiment_id \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 145\u001b[0m     experiment \u001b[38;5;241m=\u001b[39m \u001b[43mclient\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_experiment_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    146\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m experiment:\n\u001b[0;32m    147\u001b[0m         _logger\u001b[38;5;241m.\u001b[39minfo(\n\u001b[0;32m    148\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExperiment with name \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist. Creating a new experiment.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    149\u001b[0m             experiment_name,\n\u001b[0;32m    150\u001b[0m         )\n",
      "File \u001b[1;32mc:\\Users\\HP\\OneDrive\\Documents\\projet7\\venv\\Lib\\site-packages\\mlflow\\tracking\\client.py:1256\u001b[0m, in \u001b[0;36mMlflowClient.get_experiment_by_name\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1224\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_experiment_by_name\u001b[39m(\u001b[38;5;28mself\u001b[39m, name: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Optional[Experiment]:\n\u001b[0;32m   1225\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Retrieve an experiment by experiment name from the backend store\u001b[39;00m\n\u001b[0;32m   1226\u001b[0m \n\u001b[0;32m   1227\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1254\u001b[0m \u001b[38;5;124;03m        Lifecycle_stage: active\u001b[39;00m\n\u001b[0;32m   1255\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 1256\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracking_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_experiment_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HP\\OneDrive\\Documents\\projet7\\venv\\Lib\\site-packages\\mlflow\\tracking\\_tracking_service\\client.py:501\u001b[0m, in \u001b[0;36mTrackingServiceClient.get_experiment_by_name\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m    493\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_experiment_by_name\u001b[39m(\u001b[38;5;28mself\u001b[39m, name):\n\u001b[0;32m    494\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m    496\u001b[0m \u001b[38;5;124;03m        name: The experiment name.\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    499\u001b[0m \u001b[38;5;124;03m        :py:class:`mlflow.entities.Experiment`\u001b[39;00m\n\u001b[0;32m    500\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_experiment_by_name\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HP\\OneDrive\\Documents\\projet7\\venv\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py:353\u001b[0m, in \u001b[0;36mFileStore.get_experiment_by_name\u001b[1;34m(self, experiment_name)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpagination_wrapper_func\u001b[39m(number_to_get, next_page_token):\n\u001b[0;32m    346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msearch_experiments(\n\u001b[0;32m    347\u001b[0m         view_type\u001b[38;5;241m=\u001b[39mViewType\u001b[38;5;241m.\u001b[39mALL,\n\u001b[0;32m    348\u001b[0m         max_results\u001b[38;5;241m=\u001b[39mnumber_to_get,\n\u001b[0;32m    349\u001b[0m         filter_string\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    350\u001b[0m         page_token\u001b[38;5;241m=\u001b[39mnext_page_token,\n\u001b[0;32m    351\u001b[0m     )\n\u001b[1;32m--> 353\u001b[0m experiments \u001b[38;5;241m=\u001b[39m \u001b[43mget_results_from_paginated_fn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpaginated_fn\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpagination_wrapper_func\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    355\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_results_per_page\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSEARCH_MAX_RESULTS_THRESHOLD\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    356\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmax_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    357\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m experiments[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(experiments) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\OneDrive\\Documents\\projet7\\venv\\Lib\\site-packages\\mlflow\\utils\\__init__.py:238\u001b[0m, in \u001b[0;36mget_results_from_paginated_fn\u001b[1;34m(paginated_fn, max_results_per_page, max_results)\u001b[0m\n\u001b[0;32m    236\u001b[0m     page_results \u001b[38;5;241m=\u001b[39m paginated_fn(num_to_get, next_page_token)\n\u001b[0;32m    237\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 238\u001b[0m     page_results \u001b[38;5;241m=\u001b[39m \u001b[43mpaginated_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_results_per_page\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_page_token\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    239\u001b[0m all_results\u001b[38;5;241m.\u001b[39mextend(page_results)\n\u001b[0;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(page_results, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtoken\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m page_results\u001b[38;5;241m.\u001b[39mtoken:\n",
      "File \u001b[1;32mc:\\Users\\HP\\OneDrive\\Documents\\projet7\\venv\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py:346\u001b[0m, in \u001b[0;36mFileStore.get_experiment_by_name.<locals>.pagination_wrapper_func\u001b[1;34m(number_to_get, next_page_token)\u001b[0m\n\u001b[0;32m    345\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpagination_wrapper_func\u001b[39m(number_to_get, next_page_token):\n\u001b[1;32m--> 346\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_experiments\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    347\u001b[0m \u001b[43m        \u001b[49m\u001b[43mview_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mViewType\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mALL\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    348\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmax_results\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnumber_to_get\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    349\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfilter_string\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mname = \u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mexperiment_name\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m    350\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpage_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnext_page_token\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\HP\\OneDrive\\Documents\\projet7\\venv\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py:316\u001b[0m, in \u001b[0;36mFileStore.search_experiments\u001b[1;34m(self, view_type, max_results, filter_string, order_by, page_token)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m max_results \u001b[38;5;241m>\u001b[39m SEARCH_MAX_RESULTS_THRESHOLD:\n\u001b[0;32m    310\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[0;32m    311\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid value \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmax_results\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m for parameter \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmax_results\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m supplied. It must be at \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    312\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmost \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSEARCH_MAX_RESULTS_THRESHOLD\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    313\u001b[0m         INVALID_PARAMETER_VALUE,\n\u001b[0;32m    314\u001b[0m     )\n\u001b[1;32m--> 316\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_root_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    317\u001b[0m experiment_ids \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    318\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m view_type \u001b[38;5;241m==\u001b[39m ViewType\u001b[38;5;241m.\u001b[39mACTIVE_ONLY \u001b[38;5;129;01mor\u001b[39;00m view_type \u001b[38;5;241m==\u001b[39m ViewType\u001b[38;5;241m.\u001b[39mALL:\n",
      "File \u001b[1;32mc:\\Users\\HP\\OneDrive\\Documents\\projet7\\venv\\Lib\\site-packages\\mlflow\\store\\tracking\\file_store.py:210\u001b[0m, in \u001b[0;36mFileStore._check_root_dir\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    206\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    207\u001b[0m \u001b[38;5;124;03mRun checks before running directory operations.\u001b[39;00m\n\u001b[0;32m    208\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m exists(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_directory):\n\u001b[1;32m--> 210\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_directory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m does not exist.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_directory(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_directory):\n\u001b[0;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroot_directory\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not a directory.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mException\u001b[0m: 'C:\\Users\\HP\\OneDrive\\Documents\\projet7\\mlruns' does not exist."
     ]
    }
   ],
   "source": [
    "import time\n",
    "import logging\n",
    "import gc\n",
    "import mlflow\n",
    "import optuna\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialisation\n",
    "smote = SMOTE(random_state=42)\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "results_lr = []\n",
    "nb_runs = 15\n",
    "logging.getLogger('optuna').setLevel(logging.CRITICAL)\n",
    "\n",
    "# Chronomètre d'entraînement\n",
    "start_time = time.time()\n",
    "\n",
    "# Définir l'expérience MLflow\n",
    "mlflow.set_experiment('Logistic Regression Classifier')\n",
    "\n",
    "# Standardisation des données\n",
    "scaler_lr = StandardScaler()\n",
    "\n",
    "# Applique la transformation sur les données d'entraînement et de test avec la conversion en float32 pour économiser la mémoire\n",
    "X_train_eval_scaled = scaler_lr.fit_transform(X_train_eval).astype(np.float32)\n",
    "X_final_scaled = scaler_lr.transform(X_final).astype(np.float32)\n",
    "\n",
    "# Sauvegarde du scaler pour réutilisation ultérieure\n",
    "joblib.dump(scaler_lr, 'scaler_lr.joblib')\n",
    "\n",
    "# Conversion en float32 pour économiser la mémoire\n",
    "X_api_scaled = scaler_lr.transform(X_api).astype(np.float32)\n",
    "\n",
    "# Fonction de LogisticRegression pour l'optimisation Optuna\n",
    "def logistic_regression_objective(trial):\n",
    "    # Définir les hyperparamètres avec Optuna\n",
    "    C = trial.suggest_loguniform('C', 50, 200, log=True)  \n",
    "    solver = trial.suggest_categorical('solver', ['lbfgs', 'liblinear', 'saga'])\n",
    "    max_iter = trial.suggest_int('max_iter', 100, 1000)  \n",
    "\n",
    "    # Modèle de régression logistique\n",
    "    model = LogisticRegression(C=C, solver=solver, max_iter=max_iter, n_jobs=-1, random_state=42)\n",
    "    \n",
    "    auc_scores, acc_scores, cost_scores = [], [], []\n",
    "\n",
    "    # Validation croisée avec suréchantillonnage SMOTE\n",
    "    for train_idx, test_idx in cv.split(X_train_eval_scaled, y_train_eval):\n",
    "        X_train, X_test = X_train_eval_scaled[train_idx], X_train_eval_scaled[test_idx]\n",
    "        y_train, y_test = y_train_eval.iloc[train_idx].values, y_train_eval.iloc[test_idx].values\n",
    "        \n",
    "        # Appliquer SMOTE\n",
    "        X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "        model.fit(X_train_smote, y_train_smote)\n",
    "        \n",
    "        # Prédictions et probabilités\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "        y_pred = y_prob > 0.5\n",
    "\n",
    "        # Calcul des métriques\n",
    "        auc_scores.append(roc_auc_score(y_test, y_prob))\n",
    "        acc_scores.append(accuracy_score(y_test, y_pred))\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        cost_scores.append(fp + 10 * fn)\n",
    "\n",
    "    # Calcul des moyennes pour chaque métrique\n",
    "    auc = np.mean(auc_scores)\n",
    "    acc = np.mean(acc_scores)\n",
    "    cost = np.mean(cost_scores)\n",
    "\n",
    "    # Sauvegarde des résultats\n",
    "    results_lr.append({\"AUC\": auc, \"Accuracy\": acc, \"Business Score\": cost, \"C\": C, \"Solver\": solver, \"Max Iter\": max_iter})\n",
    "\n",
    "    # Enregistrement dans MLflow\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_params(trial.params)\n",
    "        mlflow.log_metrics({\"AUC\": auc, \"Accuracy\": acc, \"Business Score\": cost})\n",
    "\n",
    "        # Courbe ROC\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        plt.plot(fpr, tpr, label=f'AUC: {auc:.2f}')\n",
    "        plt.title('ROC Curve')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.savefig(\"roc_curve_lr.png\")\n",
    "        plt.close()\n",
    "        mlflow.log_artifact(\"roc_curve_lr.png\")\n",
    "\n",
    "        mlflow.sklearn.log_model(model, \"logistic_regression_model\", input_example=X_train_eval_scaled[:5])\n",
    "\n",
    "    gc.collect()\n",
    "    return cost\n",
    "\n",
    "# Optimisation avec Optuna\n",
    "study_lr = optuna.create_study(direction='minimize')\n",
    "study_lr.optimize(logistic_regression_objective, n_trials=nb_runs)\n",
    "\n",
    "# Fin du temps d'entraînement\n",
    "end_time = time.time()\n",
    "print(f\"Temps d'entraînement total: {end_time - start_time:.2f} secondes\")\n",
    "\n",
    "# Meilleurs résultats et paramètres\n",
    "best_params_lr = study_lr.best_params\n",
    "best_auc_lr = max([res['AUC'] for res in results_lr])\n",
    "best_acc_lr = max([res['Accuracy'] for res in results_lr])\n",
    "best_cost_lr = min([res['Business Score'] for res in results_lr])\n",
    "\n",
    "# Affichage des meilleurs paramètres\n",
    "print(study_lr.best_params)\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_params(best_params_lr)\n",
    "joblib.dump(best_params_lr, 'best_params_lr.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################################################################\n",
    "#2\n",
    "# Entraînement final sur toutes les données avec les meilleurs paramètres\n",
    "start_time = time.time()\n",
    "\n",
    "# Initialisation du modèle LogisticRegression avec les meilleurs paramètres obtenus\n",
    "final_model_lr = LogisticRegression(**best_params_lr, n_jobs=-1, random_state=42)\n",
    "\n",
    "# Appliquer SMOTE sur toutes les données d'entraînement\n",
    "X_train_final_smote_lr, y_train_final_smote_lr = smote.fit_resample(X_final_scaled, y_final)\n",
    "\n",
    "# Entraînement du modèle final\n",
    "final_model_lr.fit(X_train_final_smote_lr, y_train_final_smote_lr)\n",
    "\n",
    "# Affichage du temps d'entraînement final\n",
    "end_time = time.time()\n",
    "print(f\"Temps d'entraînement final: {end_time - start_time:.2f} secondes\")\n",
    "\n",
    "# Enregistrement du modèle final\n",
    "joblib.dump(final_model_lr, 'logistic_regression_model_f.joblib')\n",
    "\n",
    "# Sauvegarde des résultats dans un DataFrame\n",
    "results_df_lr = pd.DataFrame(results_lr)\n",
    "\n",
    "# Tri des résultats par Business Score croissant (du plus petit au plus grand)\n",
    "results_df_sorted_lr = results_df_lr.sort_values(by='Business Score', ascending=True)\n",
    "\n",
    "# Enregistrement des résultats dans un fichier CSV\n",
    "results_df_sorted_lr.to_csv('results_logistic_regression.csv', index=False)\n",
    "\n",
    "print(\"Les résultats ont été exportés dans 'results_logistic_regression.csv'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################################################################\n",
    "#3\n",
    "# Aplatir y_final pour le rendre compatible avec les autres colonnes 1D\n",
    "y_final = y_final.values.flatten()\n",
    "\n",
    "# Prédictions finales et métriques\n",
    "y_prob_final_lr = final_model_lr.predict_proba(X_final_scaled)[:, 1]\n",
    "y_pred_final_lr = y_prob_final_lr > 0.5\n",
    "\n",
    "# Calcul des métriques finales en utilisant y_final\n",
    "final_auc = roc_auc_score(y_final, y_prob_final_lr)\n",
    "final_accuracy = accuracy_score(y_final, y_pred_final_lr)\n",
    "tn, fp, fn, tp = confusion_matrix(y_final, y_pred_final_lr).ravel()\n",
    "final_cost = fp + 10 * fn\n",
    "\n",
    "# Création du DataFrame avec les métriques pour chaque client\n",
    "results_df_lr_f = pd.DataFrame({\n",
    "    \"SK_ID_CURR\": X_final['SK_ID_CURR'].values,  \n",
    "    \"Probabilité\": y_prob_final_lr,\n",
    "    \"Prédiction\": y_pred_final_lr,\n",
    "    \"Vrai_Label\": y_final\n",
    "})\n",
    "\n",
    "# Ajout des métriques globales en tant que nouvelles colonnes\n",
    "results_df_lr_f[\"AUC\"] = final_auc\n",
    "results_df_lr_f[\"Accuracy\"] = final_accuracy\n",
    "results_df_lr_f[\"Business Score\"] = final_cost\n",
    "\n",
    "print(\"Métriques du modèle logistic_regression final avec les meilleurs paramètres:\")\n",
    "print(f\"AUC: {final_auc:.4f}\")\n",
    "print(f\"Accuracy: {final_accuracy:.4f}\")\n",
    "print(f\"Business Score: {final_cost:.4f}\")\n",
    "\n",
    "# Affichage du DataFrame final\n",
    "results_df_lr_f.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################################################################\n",
    "\n",
    "# Prédictions finales et métriques sur X_api_scaled\n",
    "y_prob_api_lr = final_model_lr.predict_proba(X_api_scaled)[:, 1]\n",
    "y_pred_api_lr = y_prob_api_lr > 0.5\n",
    "\n",
    "# Calcul des métriques finales\n",
    "api_auc = roc_auc_score(y_api, y_prob_api_lr)\n",
    "api_accuracy = accuracy_score(y_api, y_pred_api_lr)\n",
    "tn, fp, fn, tp = confusion_matrix(y_api, y_pred_api_lr).ravel()\n",
    "api_cost = fp + 10 * fn  \n",
    "\n",
    "print(\"Métriques du modèle logistic_regression final sur les données test:\")\n",
    "print(f\"AUC: {api_auc:.4f}\")\n",
    "print(f\"Accuracy: {api_accuracy:.4f}\")\n",
    "print(f\"Business Score: {api_cost:.4f}\")\n",
    "\n",
    "# Enregistrement des métriques finales dans MLflow\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_metrics({\"Final AUC_t logistic_regression\": api_auc, \"Final Accuracy_t logistic_regression\": api_accuracy, \"Final Business Score_t logistic_regression\": api_cost})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import time\n",
    "import logging\n",
    "import gc\n",
    "import mlflow\n",
    "import optuna\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, roc_curve\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialisation\n",
    "smote = SMOTE(random_state=42)\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "results_lr = []\n",
    "nb_runs = 15\n",
    "logging.getLogger('optuna').setLevel(logging.CRITICAL)\n",
    "\n",
    "# Chronomètre d'entraînement\n",
    "start_time = time.time()\n",
    "\n",
    "# Définir l'expérience MLflow\n",
    "mlflow.set_experiment('Logistic Regression Classifier')\n",
    "\n",
    "# Standardisation des données\n",
    "scaler_lr = StandardScaler()\n",
    "\n",
    "# Applique la transformation sur les données d'entraînement et de test avec la conversion en float32 pour économiser la mémoire\n",
    "X_train_eval_scaled = scaler_lr.fit_transform(X_train_eval).astype(np.float32)\n",
    "X_final_scaled = scaler_lr.transform(X_final).astype(np.float32)\n",
    "\n",
    "# Sauvegarde du scaler pour réutilisation ultérieure\n",
    "joblib.dump(scaler_lr, 'scaler_lr.joblib')\n",
    "\n",
    "# Conversion en float32 pour économiser la mémoire\n",
    "X_api_scaled = scaler_lr.transform(X_api).astype(np.float32)\n",
    "\n",
    "# Fonction de LogisticRegression pour l'optimisation Optuna\n",
    "def logistic_regression_objective(trial):\n",
    "    # Définir les hyperparamètres avec Optuna\n",
    "    C = trial.suggest_loguniform('C', 50, 200, log=True)  \n",
    "    solver = trial.suggest_categorical('solver', ['lbfgs', 'liblinear', 'saga'])\n",
    "    max_iter = trial.suggest_int('max_iter', 100, 1000)  \n",
    "\n",
    "    # Modèle de régression logistique\n",
    "    model = LogisticRegression(C=C, solver=solver, max_iter=max_iter, n_jobs=-1, random_state=42)\n",
    "    \n",
    "    auc_scores, acc_scores, cost_scores = [], [], []\n",
    "\n",
    "    # Validation croisée avec suréchantillonnage SMOTE\n",
    "    for train_idx, test_idx in cv.split(X_train_eval_scaled, y_train_eval):\n",
    "        X_train, X_test = X_train_eval_scaled[train_idx], X_train_eval_scaled[test_idx]\n",
    "        y_train, y_test = y_train_eval.iloc[train_idx].values, y_train_eval.iloc[test_idx].values\n",
    "        \n",
    "        # Appliquer SMOTE\n",
    "        X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "        model.fit(X_train_smote, y_train_smote)\n",
    "        \n",
    "        # Prédictions et probabilités\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "        y_pred = y_prob > 0.5\n",
    "\n",
    "        # Calcul des métriques\n",
    "        auc_scores.append(roc_auc_score(y_test, y_prob))\n",
    "        acc_scores.append(accuracy_score(y_test, y_pred))\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        cost_scores.append(fp + 10 * fn)\n",
    "\n",
    "    # Calcul des moyennes pour chaque métrique\n",
    "    auc = np.mean(auc_scores)\n",
    "    acc = np.mean(acc_scores)\n",
    "    cost = np.mean(cost_scores)\n",
    "\n",
    "    # Sauvegarde des résultats\n",
    "    results_lr.append({\"AUC\": auc, \"Accuracy\": acc, \"Business Score\": cost, \"C\": C, \"Solver\": solver, \"Max Iter\": max_iter})\n",
    "\n",
    "    # Enregistrement dans MLflow\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_params(trial.params)\n",
    "        mlflow.log_metrics({\"AUC\": auc, \"Accuracy\": acc, \"Business Score\": cost})\n",
    "\n",
    "        # Courbe ROC\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        plt.plot(fpr, tpr, label=f'AUC: {auc:.2f}')\n",
    "        plt.title('ROC Curve')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.savefig(\"roc_curve_lr.png\")\n",
    "        plt.close()\n",
    "        mlflow.log_artifact(\"roc_curve_lr.png\")\n",
    "\n",
    "        mlflow.sklearn.log_model(model, \"logistic_regression_model\", input_example=X_train_eval_scaled[:5])\n",
    "\n",
    "    gc.collect()\n",
    "    return cost\n",
    "\n",
    "# Optimisation avec Optuna\n",
    "study_lr = optuna.create_study(direction='minimize')\n",
    "study_lr.optimize(logistic_regression_objective, n_trials=nb_runs)\n",
    "\n",
    "# Fin du temps d'entraînement\n",
    "end_time = time.time()\n",
    "print(f\"Temps d'entraînement total: {end_time - start_time:.2f} secondes\")\n",
    "\n",
    "# Meilleurs résultats et paramètres\n",
    "best_params_lr = study_lr.best_params\n",
    "best_auc_lr = max([res['AUC'] for res in results_lr])\n",
    "best_acc_lr = max([res['Accuracy'] for res in results_lr])\n",
    "best_cost_lr = min([res['Business Score'] for res in results_lr])\n",
    "\n",
    "# Affichage des meilleurs paramètres\n",
    "print(study_lr.best_params)\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_params(best_params_lr)\n",
    "joblib.dump(best_params_lr, 'best_params_lr.pkl')\n",
    "\n",
    "######################################################################################################################################################\n",
    "\n",
    "# Entraînement final sur toutes les données avec les meilleurs paramètres\n",
    "start_time = time.time()\n",
    "\n",
    "# Initialisation du modèle LogisticRegression avec les meilleurs paramètres obtenus\n",
    "final_model_lr = LogisticRegression(**best_params_lr, n_jobs=-1, random_state=42)\n",
    "\n",
    "# Appliquer SMOTE sur toutes les données d'entraînement\n",
    "X_train_final_smote_lr, y_train_final_smote_lr = smote.fit_resample(X_final_scaled, y_final)\n",
    "\n",
    "# Entraînement du modèle final\n",
    "final_model_lr.fit(X_train_final_smote_lr, y_train_final_smote_lr)\n",
    "\n",
    "# Affichage du temps d'entraînement final\n",
    "end_time = time.time()\n",
    "print(f\"Temps d'entraînement final: {end_time - start_time:.2f} secondes\")\n",
    "\n",
    "# Enregistrement du modèle final\n",
    "joblib.dump(final_model_lr, 'logistic_regression_model_f.joblib')\n",
    "\n",
    "# Sauvegarde des résultats dans un DataFrame\n",
    "results_df_lr = pd.DataFrame(results_lr)\n",
    "\n",
    "# Tri des résultats par Business Score croissant (du plus petit au plus grand)\n",
    "results_df_sorted_lr = results_df_lr.sort_values(by='Business Score', ascending=True)\n",
    "\n",
    "# Enregistrement des résultats dans un fichier CSV\n",
    "results_df_sorted_lr.to_csv('results_logistic_regression.csv', index=False)\n",
    "\n",
    "print(\"Les résultats ont été exportés dans 'results_logistic_regression.csv'\")\n",
    "\n",
    "######################################################################################################################################################\n",
    "\n",
    "# Prédictions finales et métriques\n",
    "y_prob_final_lr = final_model_lr.predict_proba(X_final_scaled)[:, 1]\n",
    "y_pred_final_lr = y_prob_final_lr > 0.5\n",
    "\n",
    "# Calcul des métriques finales en utilisant y_final\n",
    "final_auc = roc_auc_score(y_final, y_prob_final_lr)\n",
    "final_accuracy = accuracy_score(y_final, y_pred_final_lr)\n",
    "tn, fp, fn, tp = confusion_matrix(y_final, y_pred_final_lr).ravel()\n",
    "final_cost = fp + 10 * fn\n",
    "\n",
    "# Création du DataFrame avec les métriques pour chaque client\n",
    "results_df_lr_f = pd.DataFrame({\n",
    "    \"SK_ID_CURR\": X_final['SK_ID_CURR'].values,  \n",
    "    \"Probabilité\": y_prob_final_lr,\n",
    "    \"Prédiction\": y_pred_final_lr,\n",
    "    \"Vrai_Label\": y_final\n",
    "})\n",
    "\n",
    "# Ajout des métriques globales en tant que nouvelles colonnes\n",
    "results_df_lr_f[\"AUC\"] = final_auc\n",
    "results_df_lr_f[\"Accuracy\"] = final_accuracy\n",
    "results_df_lr_f[\"Business Score\"] = final_cost\n",
    "\n",
    "print(\"Métriques du modèle logistic_regression final avec les meilleurs paramètres:\")\n",
    "print(f\"AUC: {final_auc:.4f}\")\n",
    "print(f\"Accuracy: {final_accuracy:.4f}\")\n",
    "print(f\"Business Score: {final_cost:.4f}\")\n",
    "\n",
    "# Affichage du DataFrame final\n",
    "results_df_lr_f.head(10)\n",
    "\n",
    "######################################################################################################################################################\n",
    "\n",
    "# Prédictions finales et métriques sur X_api_scaled\n",
    "y_prob_api_lr = final_model_lr.predict_proba(X_api_scaled)[:, 1]\n",
    "y_pred_api_lr = y_prob_api_lr > 0.5\n",
    "\n",
    "# Calcul des métriques finales\n",
    "api_auc = roc_auc_score(y_api, y_prob_api_lr)\n",
    "api_accuracy = accuracy_score(y_api, y_pred_api_lr)\n",
    "tn, fp, fn, tp = confusion_matrix(y_api, y_pred_api_lr).ravel()\n",
    "api_cost = fp + 10 * fn  \n",
    "\n",
    "print(\"Métriques du modèle logistic_regression final sur les données test:\")\n",
    "print(f\"AUC: {api_auc:.4f}\")\n",
    "print(f\"Accuracy: {api_accuracy:.4f}\")\n",
    "print(f\"Business Score: {api_cost:.4f}\")\n",
    "\n",
    "# Enregistrement des métriques finales dans MLflow\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_metrics({\"Final AUC_t logistic_regression\": api_auc, \"Final Accuracy_t logistic_regression\": api_accuracy, \"Final Business Score_t logistic_regression\": api_cost})\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Random Forest avec SMOTE et SCaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "import gc\n",
    "import mlflow\n",
    "import optuna\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialisation\n",
    "smote = SMOTE(random_state=42)\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "results_rf = []\n",
    "nb_runs = 15\n",
    "logging.getLogger('optuna').setLevel(logging.CRITICAL)\n",
    "\n",
    "# Chronomètre d'entraînement\n",
    "start_time = time.time()\n",
    "\n",
    "# Définir l'expérience MLflow\n",
    "mlflow.set_experiment('Random Forest Classifier')\n",
    "\n",
    "# Standardisation des données\n",
    "scaler_rf = StandardScaler()\n",
    "\n",
    "# Applique la transformation sur les données d'entraînement et de test avec la conversion en float32 pour économiser la mémoire\n",
    "X_train_eval_scaled = scaler_rf.fit_transform(X_train_eval).astype(np.float32)\n",
    "X_final_scaled = scaler_rf.transform(X_final).astype(np.float32)\n",
    "\n",
    "# Sauvegarde du scaler pour réutilisation ultérieure\n",
    "joblib.dump(scaler_rf, 'scaler_rf.joblib')\n",
    "\n",
    "# Conversion en float32 pour économiser la mémoire\n",
    "X_api_scaled = scaler_rf.transform(X_api).astype(np.float32)\n",
    "\n",
    "# Fonction de RandomForestClassifier pour l'optimisation Optuna\n",
    "def random_forest_objective(trial):\n",
    "    # Définir les hyperparamètres avec Optuna\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300, step=50)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 20, step=1)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20, step=2)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20, step=2)\n",
    "    max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
    "\n",
    "    # Modèle de RandomForestClassifier\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, \n",
    "                                   min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf,\n",
    "                                   max_features=max_features, n_jobs=-1, random_state=42)\n",
    "    \n",
    "    auc_scores, acc_scores, cost_scores = [], [], []\n",
    "\n",
    "    # Validation croisée avec suréchantillonnage SMOTE\n",
    "    for train_idx, test_idx in cv.split(X_train_eval_scaled, y_train_eval):\n",
    "        X_train, X_test = X_train_eval_scaled[train_idx], X_train_eval_scaled[test_idx]\n",
    "        y_train, y_test = y_train_eval.iloc[train_idx].values, y_train_eval.iloc[test_idx].values\n",
    "        \n",
    "        # Appliquer SMOTE\n",
    "        X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "        model.fit(X_train_smote, y_train_smote)\n",
    "        \n",
    "        # Prédictions et probabilités\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "        y_pred = y_prob > 0.5\n",
    "\n",
    "        # Calcul des métriques\n",
    "        auc_scores.append(roc_auc_score(y_test, y_prob))\n",
    "        acc_scores.append(accuracy_score(y_test, y_pred))\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        cost_scores.append(fp + 10 * fn)\n",
    "\n",
    "    # Calcul des moyennes pour chaque métrique\n",
    "    auc = np.mean(auc_scores)\n",
    "    acc = np.mean(acc_scores)\n",
    "    cost = np.mean(cost_scores)\n",
    "\n",
    "    # Sauvegarde des résultats\n",
    "    results_rf.append({\"AUC\": auc, \"Accuracy\": acc, \"Business Score\": cost, \"n_estimators\": n_estimators, \n",
    "                       \"max_depth\": max_depth, \"min_samples_split\": min_samples_split, \n",
    "                       \"min_samples_leaf\": min_samples_leaf, \"max_features\": max_features})\n",
    "\n",
    "    # Enregistrement dans MLflow\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_params(trial.params)\n",
    "        mlflow.log_metrics({\"AUC\": auc, \"Accuracy\": acc, \"Business Score\": cost})\n",
    "\n",
    "        # Courbe ROC\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        plt.plot(fpr, tpr, label=f'AUC: {auc:.2f}')\n",
    "        plt.title('ROC Curve')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.savefig(\"roc_curve_rf.png\")\n",
    "        plt.close()\n",
    "        mlflow.log_artifact(\"roc_curve_rf.png\")\n",
    "\n",
    "        mlflow.sklearn.log_model(model, \"random_forest_model\", input_example=X_train_eval_scaled[:5])\n",
    "\n",
    "    gc.collect()\n",
    "    return cost\n",
    "\n",
    "# Optimisation avec Optuna\n",
    "study_rf = optuna.create_study(direction='minimize')\n",
    "study_rf.optimize(random_forest_objective, n_trials=nb_runs)\n",
    "\n",
    "# Fin du temps d'entraînement\n",
    "end_time = time.time()\n",
    "print(f\"Temps d'entraînement total: {end_time - start_time:.2f} secondes\")\n",
    "\n",
    "# Meilleurs résultats et paramètres\n",
    "best_params_rf = study_rf.best_params\n",
    "best_auc_rf = max([res['AUC'] for res in results_rf])\n",
    "best_acc_rf = max([res['Accuracy'] for res in results_rf])\n",
    "best_cost_rf = min([res['Business Score'] for res in results_rf])\n",
    "\n",
    "# Affichage des meilleurs paramètres\n",
    "print(study_rf.best_params)\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_params(best_params_rf)\n",
    "joblib.dump(best_params_rf, 'best_params_rf.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################################################################\n",
    "\n",
    "# Entraînement final sur toutes les données avec les meilleurs paramètres\n",
    "start_time = time.time()\n",
    "\n",
    "# Initialisation du modèle RandomForestClassifier avec les meilleurs paramètres obtenus\n",
    "final_model_rf = RandomForestClassifier(**best_params_rf, n_jobs=-1, random_state=42)\n",
    "\n",
    "# Appliquer SMOTE sur toutes les données d'entraînement\n",
    "X_train_final_smote_rf, y_train_final_smote_rf = smote.fit_resample(X_final_scaled, y_final)\n",
    "\n",
    "# Entraînement du modèle final\n",
    "final_model_rf.fit(X_train_final_smote_rf, y_train_final_smote_rf)\n",
    "\n",
    "# Affichage du temps d'entraînement final\n",
    "end_time = time.time()\n",
    "print(f\"Temps d'entraînement final: {end_time - start_time:.2f} secondes\")\n",
    "\n",
    "# Enregistrement du modèle final\n",
    "joblib.dump(final_model_rf, 'random_forest_model_f.joblib')\n",
    "\n",
    "# Sauvegarde des résultats dans un DataFrame\n",
    "results_df_rf = pd.DataFrame(results_rf)\n",
    "\n",
    "# Tri des résultats par Business Score croissant (du plus petit au plus grand)\n",
    "results_df_sorted_rf = results_df_rf.sort_values(by='Business Score', ascending=True)\n",
    "\n",
    "# Enregistrement des résultats dans un fichier CSV\n",
    "results_df_sorted_rf.to_csv('results_random_forest.csv', index=False)\n",
    "\n",
    "print(\"Les résultats ont été exportés dans 'results_random_forest.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################################################################\n",
    "\n",
    "# Prédictions finales et métriques\n",
    "y_prob_final_rf = final_model_rf.predict_proba(X_final_scaled)[:, 1]\n",
    "y_pred_final_rf = y_prob_final_rf > 0.5\n",
    "\n",
    "# Calcul des métriques finales en utilisant y_final\n",
    "final_auc = roc_auc_score(y_final, y_prob_final_rf)\n",
    "final_accuracy = accuracy_score(y_final, y_pred_final_rf)\n",
    "tn, fp, fn, tp = confusion_matrix(y_final, y_pred_final_rf).ravel()\n",
    "final_cost = fp + 10 * fn\n",
    "\n",
    "# Création du DataFrame avec les métriques pour chaque client\n",
    "results_df_rf_f = pd.DataFrame({\n",
    "    \"SK_ID_CURR\": X_final['SK_ID_CURR'].values,  \n",
    "    \"Probabilité\": y_prob_final_rf,\n",
    "    \"Prédiction\": y_pred_final_rf,\n",
    "    \"Vrai_Label\": y_final\n",
    "})\n",
    "\n",
    "# Ajout des métriques globales en tant que nouvelles colonnes\n",
    "results_df_rf_f[\"AUC\"] = final_auc\n",
    "results_df_rf_f[\"Accuracy\"] = final_accuracy\n",
    "results_df_rf_f[\"Business Score\"] = final_cost\n",
    "\n",
    "print(\"Métriques du modèle random_forest final avec les meilleurs paramètres:\")\n",
    "print(f\"AUC: {final_auc:.4f}\")\n",
    "print(f\"Accuracy: {final_accuracy:.4f}\")\n",
    "print(f\"Business Score: {final_cost:.4f}\")\n",
    "\n",
    "# Affichage du DataFrame final\n",
    "results_df_rf_f.head(10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################################################################\n",
    "\n",
    "# Prédictions finales et métriques sur X_api_scaled\n",
    "y_prob_api_rf = final_model_rf.predict_proba(X_api_scaled)[:, 1]\n",
    "y_pred_api_rf = y_prob_api_rf > 0.5\n",
    "\n",
    "# Calcul des métriques finales\n",
    "api_auc = roc_auc_score(y_api, y_prob_api_rf)\n",
    "api_accuracy = accuracy_score(y_api, y_pred_api_rf)\n",
    "tn, fp, fn, tp = confusion_matrix(y_api, y_pred_api_rf).ravel()\n",
    "api_cost = fp + 10 * fn  \n",
    "\n",
    "print(\"Métriques du modèle random_forest final sur les données test:\")\n",
    "print(f\"AUC: {api_auc:.4f}\")\n",
    "print(f\"Accuracy: {api_accuracy:.4f}\")\n",
    "print(f\"Business Score: {api_cost:.4f}\")\n",
    "\n",
    "# Enregistrement des métriques finales dans MLflow\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_metrics({\"Final AUC_t random_forest\": api_auc, \n",
    "                        \"Final Accuracy_t random_forest\": api_accuracy, \n",
    "                        \"Final Business Score_t random_forest\": api_cost})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import time\n",
    "import logging\n",
    "import gc\n",
    "import mlflow\n",
    "import optuna\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, roc_curve\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialisation\n",
    "smote = SMOTE(random_state=42)\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "results_rf = []\n",
    "nb_runs = 15\n",
    "logging.getLogger('optuna').setLevel(logging.CRITICAL)\n",
    "\n",
    "# Chronomètre d'entraînement\n",
    "start_time = time.time()\n",
    "\n",
    "# Définir l'expérience MLflow\n",
    "mlflow.set_experiment('Random Forest Classifier')\n",
    "\n",
    "# Standardisation des données\n",
    "scaler_rf = StandardScaler()\n",
    "\n",
    "# Applique la transformation sur les données d'entraînement et de test avec la conversion en float32 pour économiser la mémoire\n",
    "X_train_eval_scaled = scaler_rf.fit_transform(X_train_eval).astype(np.float32)\n",
    "X_final_scaled = scaler_rf.transform(X_final).astype(np.float32)\n",
    "\n",
    "# Sauvegarde du scaler pour réutilisation ultérieure\n",
    "joblib.dump(scaler_rf, 'scaler_rf.joblib')\n",
    "\n",
    "# Conversion en float32 pour économiser la mémoire\n",
    "X_api_scaled = scaler_rf.transform(X_api).astype(np.float32)\n",
    "\n",
    "# Fonction de RandomForestClassifier pour l'optimisation Optuna\n",
    "def random_forest_objective(trial):\n",
    "    # Définir les hyperparamètres avec Optuna\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 300, step=50)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 20, step=1)\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 20, step=2)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 20, step=2)\n",
    "    max_features = trial.suggest_categorical('max_features', ['sqrt', 'log2', None])\n",
    "\n",
    "    # Modèle de RandomForestClassifier\n",
    "    model = RandomForestClassifier(n_estimators=n_estimators, max_depth=max_depth, \n",
    "                                   min_samples_split=min_samples_split, min_samples_leaf=min_samples_leaf,\n",
    "                                   max_features=max_features, n_jobs=-1, random_state=42)\n",
    "    \n",
    "    auc_scores, acc_scores, cost_scores = [], [], []\n",
    "\n",
    "    # Validation croisée avec suréchantillonnage SMOTE\n",
    "    for train_idx, test_idx in cv.split(X_train_eval_scaled, y_train_eval):\n",
    "        X_train, X_test = X_train_eval_scaled[train_idx], X_train_eval_scaled[test_idx]\n",
    "        y_train, y_test = y_train_eval.iloc[train_idx].values, y_train_eval.iloc[test_idx].values\n",
    "        \n",
    "        # Appliquer SMOTE\n",
    "        X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "        model.fit(X_train_smote, y_train_smote)\n",
    "        \n",
    "        # Prédictions et probabilités\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "        y_pred = y_prob > 0.5\n",
    "\n",
    "        # Calcul des métriques\n",
    "        auc_scores.append(roc_auc_score(y_test, y_prob))\n",
    "        acc_scores.append(accuracy_score(y_test, y_pred))\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        cost_scores.append(fp + 10 * fn)\n",
    "\n",
    "    # Calcul des moyennes pour chaque métrique\n",
    "    auc = np.mean(auc_scores)\n",
    "    acc = np.mean(acc_scores)\n",
    "    cost = np.mean(cost_scores)\n",
    "\n",
    "    # Sauvegarde des résultats\n",
    "    results_rf.append({\"AUC\": auc, \"Accuracy\": acc, \"Business Score\": cost, \"n_estimators\": n_estimators, \n",
    "                       \"max_depth\": max_depth, \"min_samples_split\": min_samples_split, \n",
    "                       \"min_samples_leaf\": min_samples_leaf, \"max_features\": max_features})\n",
    "\n",
    "    # Enregistrement dans MLflow\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_params(trial.params)\n",
    "        mlflow.log_metrics({\"AUC\": auc, \"Accuracy\": acc, \"Business Score\": cost})\n",
    "\n",
    "        # Courbe ROC\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        plt.plot(fpr, tpr, label=f'AUC: {auc:.2f}')\n",
    "        plt.title('ROC Curve')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.savefig(\"roc_curve_rf.png\")\n",
    "        plt.close()\n",
    "        mlflow.log_artifact(\"roc_curve_rf.png\")\n",
    "\n",
    "        mlflow.sklearn.log_model(model, \"random_forest_model\", input_example=X_train_eval_scaled[:5])\n",
    "\n",
    "    gc.collect()\n",
    "    return cost\n",
    "\n",
    "# Optimisation avec Optuna\n",
    "study_rf = optuna.create_study(direction='minimize')\n",
    "study_rf.optimize(random_forest_objective, n_trials=nb_runs)\n",
    "\n",
    "# Fin du temps d'entraînement\n",
    "end_time = time.time()\n",
    "print(f\"Temps d'entraînement total: {end_time - start_time:.2f} secondes\")\n",
    "\n",
    "# Meilleurs résultats et paramètres\n",
    "best_params_rf = study_rf.best_params\n",
    "best_auc_rf = max([res['AUC'] for res in results_rf])\n",
    "best_acc_rf = max([res['Accuracy'] for res in results_rf])\n",
    "best_cost_rf = min([res['Business Score'] for res in results_rf])\n",
    "\n",
    "# Affichage des meilleurs paramètres\n",
    "print(study_rf.best_params)\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_params(best_params_rf)\n",
    "joblib.dump(best_params_rf, 'best_params_rf.pkl')\n",
    "\n",
    "######################################################################################################################################################\n",
    "\n",
    "# Entraînement final sur toutes les données avec les meilleurs paramètres\n",
    "start_time = time.time()\n",
    "\n",
    "# Initialisation du modèle RandomForestClassifier avec les meilleurs paramètres obtenus\n",
    "final_model_rf = RandomForestClassifier(**best_params_rf, n_jobs=-1, random_state=42)\n",
    "\n",
    "# Appliquer SMOTE sur toutes les données d'entraînement\n",
    "X_train_final_smote_rf, y_train_final_smote_rf = smote.fit_resample(X_final_scaled, y_final)\n",
    "\n",
    "# Entraînement du modèle final\n",
    "final_model_rf.fit(X_train_final_smote_rf, y_train_final_smote_rf)\n",
    "\n",
    "# Affichage du temps d'entraînement final\n",
    "end_time = time.time()\n",
    "print(f\"Temps d'entraînement final: {end_time - start_time:.2f} secondes\")\n",
    "\n",
    "# Enregistrement du modèle final\n",
    "joblib.dump(final_model_rf, 'random_forest_model_f.joblib')\n",
    "\n",
    "# Sauvegarde des résultats dans un DataFrame\n",
    "results_df_rf = pd.DataFrame(results_rf)\n",
    "\n",
    "# Tri des résultats par Business Score croissant (du plus petit au plus grand)\n",
    "results_df_sorted_rf = results_df_rf.sort_values(by='Business Score', ascending=True)\n",
    "\n",
    "# Enregistrement des résultats dans un fichier CSV\n",
    "results_df_sorted_rf.to_csv('results_random_forest.csv', index=False)\n",
    "\n",
    "print(\"Les résultats ont été exportés dans 'results_random_forest.csv'\")\n",
    "\n",
    "######################################################################################################################################################\n",
    "\n",
    "# Prédictions finales et métriques\n",
    "y_prob_final_rf = final_model_rf.predict_proba(X_final_scaled)[:, 1]\n",
    "y_pred_final_rf = y_prob_final_rf > 0.5\n",
    "\n",
    "# Calcul des métriques finales en utilisant y_final\n",
    "final_auc = roc_auc_score(y_final, y_prob_final_rf)\n",
    "final_accuracy = accuracy_score(y_final, y_pred_final_rf)\n",
    "tn, fp, fn, tp = confusion_matrix(y_final, y_pred_final_rf).ravel()\n",
    "final_cost = fp + 10 * fn\n",
    "\n",
    "# Création du DataFrame avec les métriques pour chaque client\n",
    "results_df_rf_f = pd.DataFrame({\n",
    "    \"SK_ID_CURR\": X_final['SK_ID_CURR'].values,  \n",
    "    \"Probabilité\": y_prob_final_rf,\n",
    "    \"Prédiction\": y_pred_final_rf,\n",
    "    \"Vrai_Label\": y_final\n",
    "})\n",
    "\n",
    "# Ajout des métriques globales en tant que nouvelles colonnes\n",
    "results_df_rf_f[\"AUC\"] = final_auc\n",
    "results_df_rf_f[\"Accuracy\"] = final_accuracy\n",
    "results_df_rf_f[\"Business Score\"] = final_cost\n",
    "\n",
    "print(\"Métriques du modèle random_forest final avec les meilleurs paramètres:\")\n",
    "print(f\"AUC: {final_auc:.4f}\")\n",
    "print(f\"Accuracy: {final_accuracy:.4f}\")\n",
    "print(f\"Business Score: {final_cost:.4f}\")\n",
    "\n",
    "# Affichage du DataFrame final\n",
    "results_df_rf_f.head(10)\n",
    "\n",
    "######################################################################################################################################################\n",
    "\n",
    "# Prédictions finales et métriques sur X_api_scaled\n",
    "y_prob_api_rf = final_model_rf.predict_proba(X_api_scaled)[:, 1]\n",
    "y_pred_api_rf = y_prob_api_rf > 0.5\n",
    "\n",
    "# Calcul des métriques finales\n",
    "api_auc = roc_auc_score(y_api, y_prob_api_rf)\n",
    "api_accuracy = accuracy_score(y_api, y_pred_api_rf)\n",
    "tn, fp, fn, tp = confusion_matrix(y_api, y_pred_api_rf).ravel()\n",
    "api_cost = fp + 10 * fn  \n",
    "\n",
    "print(\"Métriques du modèle random_forest final sur les données test:\")\n",
    "print(f\"AUC: {api_auc:.4f}\")\n",
    "print(f\"Accuracy: {api_accuracy:.4f}\")\n",
    "print(f\"Business Score: {api_cost:.4f}\")\n",
    "\n",
    "# Enregistrement des métriques finales dans MLflow\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_metrics({\"Final AUC_t random_forest\": api_auc, \n",
    "                        \"Final Accuracy_t random_forest\": api_accuracy, \n",
    "                        \"Final Business Score_t random_forest\": api_cost})'''\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#light GBM avec smote et scaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import logging\n",
    "import gc\n",
    "import mlflow\n",
    "import optuna\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, roc_curve\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialisation\n",
    "smote = SMOTE(random_state=42)\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "results_lgbm = []\n",
    "nb_runs = 15\n",
    "logging.getLogger('optuna').setLevel(logging.CRITICAL)\n",
    "\n",
    "# Chronomètre d'entraînement\n",
    "start_time = time.time()\n",
    "\n",
    "# Définir l'expérience MLflow\n",
    "mlflow.set_experiment('LightGBM Classifier')\n",
    "\n",
    "# Standardisation des données\n",
    "scaler_lgbm = StandardScaler()\n",
    "\n",
    "# Applique la transformation sur les données d'entraînement et de test avec la conversion en float32 pour économiser la mémoire\n",
    "X_train_eval_scaled = scaler_lgbm.fit_transform(X_train_eval).astype(np.float32)\n",
    "X_final_scaled = scaler_lgbm.transform(X_final).astype(np.float32)\n",
    "\n",
    "# Sauvegarde du scaler pour réutilisation ultérieure\n",
    "joblib.dump(scaler_lgbm, 'scaler_lgbm.joblib')\n",
    "\n",
    "# Conversion en float32 pour économiser la mémoire\n",
    "X_api_scaled = scaler_lgbm.transform(X_api).astype(np.float32)\n",
    "\n",
    "# Fonction de LightGBM pour l'optimisation Optuna\n",
    "def lightgbm_objective(trial):\n",
    "    # Définir les hyperparamètres avec Optuna\n",
    "    force_col_wise=True,\n",
    "    num_leaves = trial.suggest_int('num_leaves', 30, 50)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 20)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.001, 0.1, log=True)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 1000, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    colsample_bytree = trial.suggest_float('colsample_bytree', 0.6, 1.0)\n",
    "\n",
    "    # Modèle de LightGBM\n",
    "    model = lgb.LGBMClassifier(num_leaves=num_leaves, max_depth=max_depth, \n",
    "                               learning_rate=learning_rate, n_estimators=n_estimators,\n",
    "                               subsample=subsample, colsample_bytree=colsample_bytree, \n",
    "                               n_jobs=-1, random_state=42)\n",
    "    \n",
    "    auc_scores, acc_scores, cost_scores = [], [], []\n",
    "\n",
    "    # Validation croisée avec suréchantillonnage SMOTE\n",
    "    for train_idx, test_idx in cv.split(X_train_eval_scaled, y_train_eval):\n",
    "        X_train, X_test = X_train_eval_scaled[train_idx], X_train_eval_scaled[test_idx]\n",
    "        y_train, y_test = y_train_eval.iloc[train_idx].values, y_train_eval.iloc[test_idx].values\n",
    "        \n",
    "        # Appliquer SMOTE\n",
    "        X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "        model.fit(X_train_smote, y_train_smote)\n",
    "        \n",
    "        # Prédictions et probabilités\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "        y_pred = y_prob > 0.5\n",
    "\n",
    "        # Calcul des métriques\n",
    "        auc_scores.append(roc_auc_score(y_test, y_prob))\n",
    "        acc_scores.append(accuracy_score(y_test, y_pred))\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        cost_scores.append(fp + 10 * fn)\n",
    "\n",
    "    # Calcul des moyennes pour chaque métrique\n",
    "    auc = np.mean(auc_scores)\n",
    "    acc = np.mean(acc_scores)\n",
    "    cost = np.mean(cost_scores)\n",
    "\n",
    "    # Sauvegarde des résultats\n",
    "    results_lgbm.append({\"AUC\": auc, \"Accuracy\": acc, \"Business Score\": cost, \n",
    "                         \"num_leaves\": num_leaves, \"max_depth\": max_depth, \n",
    "                         \"learning_rate\": learning_rate, \"n_estimators\": n_estimators, \n",
    "                         \"subsample\": subsample, \"colsample_bytree\": colsample_bytree})\n",
    "\n",
    "    # Enregistrement dans MLflow\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_params(trial.params)\n",
    "        mlflow.log_metrics({\"AUC\": auc, \"Accuracy\": acc, \"Business Score\": cost})\n",
    "\n",
    "        # Courbe ROC\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        plt.plot(fpr, tpr, label=f'AUC: {auc:.2f}')\n",
    "        plt.title('ROC Curve')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.savefig(\"roc_curve_lgbm.png\")\n",
    "        plt.close()\n",
    "        mlflow.log_artifact(\"roc_curve_lgbm.png\")\n",
    "\n",
    "        mlflow.lightgbm.log_model(model, \"lightgbm_model\", input_example=X_train_eval_scaled[:5])\n",
    "\n",
    "    gc.collect()\n",
    "    return cost\n",
    "\n",
    "# Optimisation avec Optuna\n",
    "study_lgbm = optuna.create_study(direction='minimize')\n",
    "study_lgbm.optimize(lightgbm_objective, n_trials=nb_runs)\n",
    "\n",
    "# Fin du temps d'entraînement\n",
    "end_time = time.time()\n",
    "print(f\"Temps d'entraînement total: {end_time - start_time:.2f} secondes\")\n",
    "\n",
    "# Meilleurs résultats et paramètres\n",
    "best_params_lgbm = study_lgbm.best_params\n",
    "best_auc_lgbm = max([res['AUC'] for res in results_lgbm])\n",
    "best_acc_lgbm = max([res['Accuracy'] for res in results_lgbm])\n",
    "best_cost_lgbm = min([res['Business Score'] for res in results_lgbm])\n",
    "\n",
    "# Affichage des meilleurs paramètres\n",
    "print(study_lgbm.best_params)\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_params(best_params_lgbm)\n",
    "joblib.dump(best_params_lgbm, 'best_params_lgbm.pkl')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################################################################\n",
    "\n",
    "# Entraînement final sur toutes les données avec les meilleurs paramètres\n",
    "start_time = time.time()\n",
    "\n",
    "# Initialisation du modèle LightGBM avec les meilleurs paramètres obtenus\n",
    "final_model_lgbm = lgb.LGBMClassifier(**best_params_lgbm, n_jobs=-1, random_state=42)\n",
    "\n",
    "# Appliquer SMOTE sur toutes les données d'entraînement\n",
    "X_train_final_smote_lgbm, y_train_final_smote_lgbm = smote.fit_resample(X_final_scaled, y_final)\n",
    "\n",
    "# Entraînement du modèle final\n",
    "final_model_lgbm.fit(X_train_final_smote_lgbm, y_train_final_smote_lgbm)\n",
    "\n",
    "# Affichage du temps d'entraînement final\n",
    "end_time = time.time()\n",
    "print(f\"Temps d'entraînement final: {end_time - start_time:.2f} secondes\")\n",
    "\n",
    "# Enregistrement du modèle final\n",
    "joblib.dump(final_model_lgbm, 'lightgbm_model_f.joblib')\n",
    "\n",
    "# Sauvegarde des résultats dans un DataFrame\n",
    "results_df_lgbm = pd.DataFrame(results_lgbm)\n",
    "\n",
    "# Tri des résultats par Business Score croissant (du plus petit au plus grand)\n",
    "results_df_sorted_lgbm = results_df_lgbm.sort_values(by='Business Score', ascending=True)\n",
    "\n",
    "# Enregistrement des résultats dans un fichier CSV\n",
    "results_df_sorted_lgbm.to_csv('results_lightgbm.csv', index=False)\n",
    "\n",
    "print(\"Les résultats ont été exportés dans 'results_lightgbm.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################################################################\n",
    "\n",
    "# Prédictions finales et métriques\n",
    "y_prob_final_lgbm = final_model_lgbm.predict_proba(X_final_scaled)[:, 1]\n",
    "y_pred_final_lgbm = y_prob_final_lgbm > 0.5\n",
    "\n",
    "# Calcul des métriques finales en utilisant y_final\n",
    "final_auc = roc_auc_score(y_final, y_prob_final_lgbm)\n",
    "final_accuracy = accuracy_score(y_final, y_pred_final_lgbm)\n",
    "tn, fp, fn, tp = confusion_matrix(y_final, y_pred_final_lgbm).ravel()\n",
    "final_cost = fp + 10 * fn\n",
    "\n",
    "# Création du DataFrame avec les métriques pour chaque client\n",
    "results_df_lgbm_f = pd.DataFrame({\n",
    "    \"SK_ID_CURR\": X_final['SK_ID_CURR'].values,  \n",
    "    \"Probabilité\": y_prob_final_lgbm,\n",
    "    \"Prédiction\": y_pred_final_lgbm,\n",
    "    \"Vrai_Label\": y_final\n",
    "})\n",
    "\n",
    "# Ajout des métriques globales en tant que nouvelles colonnes\n",
    "results_df_lgbm_f[\"AUC\"] = final_auc\n",
    "results_df_lgbm_f[\"Accuracy\"] = final_accuracy\n",
    "results_df_lgbm_f[\"Business Score\"] = final_cost\n",
    "\n",
    "print(\"Métriques du modèle lightgbm final avec les meilleurs paramètres:\")\n",
    "print(f\"AUC: {final_auc:.4f}\")\n",
    "print(f\"Accuracy: {final_accuracy:.4f}\")\n",
    "print(f\"Business Score: {final_cost:.4f}\")\n",
    "\n",
    "# Affichage du DataFrame final\n",
    "results_df_lgbm_f.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################################################################################################################################\n",
    "\n",
    "# Prédictions finales et métriques sur les données de test API\n",
    "X_api_scaled = scaler_lgbm.transform(X_api).astype(np.float32)\n",
    "\n",
    "y_prob_final_lgbm = final_model_lgbm.predict_proba(X_api_scaled)[:, 1]\n",
    "y_pred_final_lgbm = y_prob_final_lgbm > 0.5\n",
    "\n",
    "# Calcul des métriques finales\n",
    "api_auc = roc_auc_score(y_api, y_prob_final_lgbm)\n",
    "api_accuracy = accuracy_score(y_api, y_pred_final_lgbm)\n",
    "tn, fp, fn, tp = confusion_matrix(y_api, y_pred_final_lgbm).ravel()\n",
    "api_cost = fp + 10 * fn  \n",
    "\n",
    "print(\"Métriques du modèle lightgbm final avec les meilleurs paramètres sur les données test API:\")\n",
    "print(f\"AUC: {api_auc:.4f}\")\n",
    "print(f\"Accuracy: {api_accuracy:.4f}\")\n",
    "print(f\"Business Score: {api_cost:.4f}\")\n",
    "\n",
    "# Enregistrement des métriques finales dans MLflow\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_metrics({\"Final AUC_t lightgbm\": api_auc, \n",
    "                        \"Final Accuracy_t lightgbm\": api_accuracy, \n",
    "                        \"Final Business Score_t lightgbm\": api_cost})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''import time\n",
    "import logging\n",
    "import gc\n",
    "import mlflow\n",
    "import optuna\n",
    "import joblib\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, roc_curve\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Initialisation\n",
    "smote = SMOTE(random_state=42)\n",
    "cv = StratifiedKFold(n_splits=5)\n",
    "results_lgbm = []\n",
    "nb_runs = 15\n",
    "logging.getLogger('optuna').setLevel(logging.CRITICAL)\n",
    "\n",
    "# Chronomètre d'entraînement\n",
    "start_time = time.time()\n",
    "\n",
    "# Définir l'expérience MLflow\n",
    "mlflow.set_experiment('LightGBM Classifier')\n",
    "\n",
    "# Standardisation des données\n",
    "scaler_lgbm = StandardScaler()\n",
    "\n",
    "# Applique la transformation sur les données d'entraînement et de test avec la conversion en float32 pour économiser la mémoire\n",
    "X_train_eval_scaled = scaler_lgbm.fit_transform(X_train_eval).astype(np.float32)\n",
    "X_final_scaled = scaler_lgbm.transform(X_final).astype(np.float32)\n",
    "\n",
    "# Sauvegarde du scaler pour réutilisation ultérieure\n",
    "joblib.dump(scaler_lgbm, 'scaler_lgbm.joblib')\n",
    "\n",
    "# Conversion en float32 pour économiser la mémoire\n",
    "X_api_scaled = scaler_lgbm.transform(X_api).astype(np.float32)\n",
    "\n",
    "# Fonction de LightGBM pour l'optimisation Optuna\n",
    "def lightgbm_objective(trial):\n",
    "    # Définir les hyperparamètres avec Optuna\n",
    "    force_col_wise=True,\n",
    "    num_leaves = trial.suggest_int('num_leaves', 30, 50)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 20)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.001, 0.1, log=True)\n",
    "    n_estimators = trial.suggest_int('n_estimators', 100, 1000, log=True)\n",
    "    subsample = trial.suggest_float('subsample', 0.6, 1.0)\n",
    "    colsample_bytree = trial.suggest_float('colsample_bytree', 0.6, 1.0)\n",
    "\n",
    "    # Modèle de LightGBM\n",
    "    model = lgb.LGBMClassifier(num_leaves=num_leaves, max_depth=max_depth, \n",
    "                               learning_rate=learning_rate, n_estimators=n_estimators,\n",
    "                               subsample=subsample, colsample_bytree=colsample_bytree, \n",
    "                               n_jobs=-1, random_state=42)\n",
    "    \n",
    "    auc_scores, acc_scores, cost_scores = [], [], []\n",
    "\n",
    "    # Validation croisée avec suréchantillonnage SMOTE\n",
    "    for train_idx, test_idx in cv.split(X_train_eval_scaled, y_train_eval):\n",
    "        X_train, X_test = X_train_eval_scaled[train_idx], X_train_eval_scaled[test_idx]\n",
    "        y_train, y_test = y_train_eval.iloc[train_idx].values, y_train_eval.iloc[test_idx].values\n",
    "        \n",
    "        # Appliquer SMOTE\n",
    "        X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "        model.fit(X_train_smote, y_train_smote)\n",
    "        \n",
    "        # Prédictions et probabilités\n",
    "        y_prob = model.predict_proba(X_test)[:, 1]\n",
    "        y_pred = y_prob > 0.5\n",
    "\n",
    "        # Calcul des métriques\n",
    "        auc_scores.append(roc_auc_score(y_test, y_prob))\n",
    "        acc_scores.append(accuracy_score(y_test, y_pred))\n",
    "        tn, fp, fn, tp = confusion_matrix(y_test, y_pred).ravel()\n",
    "        cost_scores.append(fp + 10 * fn)\n",
    "\n",
    "    # Calcul des moyennes pour chaque métrique\n",
    "    auc = np.mean(auc_scores)\n",
    "    acc = np.mean(acc_scores)\n",
    "    cost = np.mean(cost_scores)\n",
    "\n",
    "    # Sauvegarde des résultats\n",
    "    results_lgbm.append({\"AUC\": auc, \"Accuracy\": acc, \"Business Score\": cost, \n",
    "                         \"num_leaves\": num_leaves, \"max_depth\": max_depth, \n",
    "                         \"learning_rate\": learning_rate, \"n_estimators\": n_estimators, \n",
    "                         \"subsample\": subsample, \"colsample_bytree\": colsample_bytree})\n",
    "\n",
    "    # Enregistrement dans MLflow\n",
    "    with mlflow.start_run():\n",
    "        mlflow.log_params(trial.params)\n",
    "        mlflow.log_metrics({\"AUC\": auc, \"Accuracy\": acc, \"Business Score\": cost})\n",
    "\n",
    "        # Courbe ROC\n",
    "        fpr, tpr, _ = roc_curve(y_test, y_prob)\n",
    "        plt.figure(figsize=(10, 7))\n",
    "        plt.plot(fpr, tpr, label=f'AUC: {auc:.2f}')\n",
    "        plt.title('ROC Curve')\n",
    "        plt.xlabel('False Positive Rate')\n",
    "        plt.ylabel('True Positive Rate')\n",
    "        plt.legend(loc='lower right')\n",
    "        plt.savefig(\"roc_curve_lgbm.png\")\n",
    "        plt.close()\n",
    "        mlflow.log_artifact(\"roc_curve_lgbm.png\")\n",
    "\n",
    "        mlflow.lightgbm.log_model(model, \"lightgbm_model\", input_example=X_train_eval_scaled[:5])\n",
    "\n",
    "    gc.collect()\n",
    "    return cost\n",
    "\n",
    "# Optimisation avec Optuna\n",
    "study_lgbm = optuna.create_study(direction='minimize')\n",
    "study_lgbm.optimize(lightgbm_objective, n_trials=nb_runs)\n",
    "\n",
    "# Fin du temps d'entraînement\n",
    "end_time = time.time()\n",
    "print(f\"Temps d'entraînement total: {end_time - start_time:.2f} secondes\")\n",
    "\n",
    "# Meilleurs résultats et paramètres\n",
    "best_params_lgbm = study_lgbm.best_params\n",
    "best_auc_lgbm = max([res['AUC'] for res in results_lgbm])\n",
    "best_acc_lgbm = max([res['Accuracy'] for res in results_lgbm])\n",
    "best_cost_lgbm = min([res['Business Score'] for res in results_lgbm])\n",
    "\n",
    "# Affichage des meilleurs paramètres\n",
    "print(study_lgbm.best_params)\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_params(best_params_lgbm)\n",
    "joblib.dump(best_params_lgbm, 'best_params_lgbm.pkl')\n",
    "\n",
    "######################################################################################################################################################\n",
    "\n",
    "# Entraînement final sur toutes les données avec les meilleurs paramètres\n",
    "start_time = time.time()\n",
    "\n",
    "# Initialisation du modèle LightGBM avec les meilleurs paramètres obtenus\n",
    "final_model_lgbm = lgb.LGBMClassifier(**best_params_lgbm, n_jobs=-1, random_state=42)\n",
    "\n",
    "# Appliquer SMOTE sur toutes les données d'entraînement\n",
    "X_train_final_smote_lgbm, y_train_final_smote_lgbm = smote.fit_resample(X_final_scaled, y_final)\n",
    "\n",
    "# Entraînement du modèle final\n",
    "final_model_lgbm.fit(X_train_final_smote_lgbm, y_train_final_smote_lgbm)\n",
    "\n",
    "# Affichage du temps d'entraînement final\n",
    "end_time = time.time()\n",
    "print(f\"Temps d'entraînement final: {end_time - start_time:.2f} secondes\")\n",
    "\n",
    "# Enregistrement du modèle final\n",
    "joblib.dump(final_model_lgbm, 'lightgbm_model_f.joblib')\n",
    "\n",
    "# Sauvegarde des résultats dans un DataFrame\n",
    "results_df_lgbm = pd.DataFrame(results_lgbm)\n",
    "\n",
    "# Tri des résultats par Business Score croissant (du plus petit au plus grand)\n",
    "results_df_sorted_lgbm = results_df_lgbm.sort_values(by='Business Score', ascending=True)\n",
    "\n",
    "# Enregistrement des résultats dans un fichier CSV\n",
    "results_df_sorted_lgbm.to_csv('results_lightgbm.csv', index=False)\n",
    "\n",
    "print(\"Les résultats ont été exportés dans 'results_lightgbm.csv'\")\n",
    "\n",
    "######################################################################################################################################################\n",
    "\n",
    "# Prédictions finales et métriques\n",
    "y_prob_final_lgbm = final_model_lgbm.predict_proba(X_final_scaled)[:, 1]\n",
    "y_pred_final_lgbm = y_prob_final_lgbm > 0.5\n",
    "\n",
    "# Calcul des métriques finales en utilisant y_final\n",
    "final_auc = roc_auc_score(y_final, y_prob_final_lgbm)\n",
    "final_accuracy = accuracy_score(y_final, y_pred_final_lgbm)\n",
    "tn, fp, fn, tp = confusion_matrix(y_final, y_pred_final_lgbm).ravel()\n",
    "final_cost = fp + 10 * fn\n",
    "\n",
    "# Création du DataFrame avec les métriques pour chaque client\n",
    "results_df_lgbm_f = pd.DataFrame({\n",
    "    \"SK_ID_CURR\": X_final['SK_ID_CURR'].values,  \n",
    "    \"Probabilité\": y_prob_final_lgbm,\n",
    "    \"Prédiction\": y_pred_final_lgbm,\n",
    "    \"Vrai_Label\": y_final\n",
    "})\n",
    "\n",
    "# Ajout des métriques globales en tant que nouvelles colonnes\n",
    "results_df_lgbm_f[\"AUC\"] = final_auc\n",
    "results_df_lgbm_f[\"Accuracy\"] = final_accuracy\n",
    "results_df_lgbm_f[\"Business Score\"] = final_cost\n",
    "\n",
    "print(\"Métriques du modèle lightgbm final avec les meilleurs paramètres:\")\n",
    "print(f\"AUC: {final_auc:.4f}\")\n",
    "print(f\"Accuracy: {final_accuracy:.4f}\")\n",
    "print(f\"Business Score: {final_cost:.4f}\")\n",
    "\n",
    "# Affichage du DataFrame final\n",
    "results_df_lgbm_f.head(10)\n",
    "\n",
    "######################################################################################################################################################\n",
    "\n",
    "# Prédictions finales et métriques sur les données de test API\n",
    "X_api_scaled = scaler_lgbm.transform(X_api).astype(np.float32)\n",
    "\n",
    "y_prob_final_lgbm = final_model_lgbm.predict_proba(X_api_scaled)[:, 1]\n",
    "y_pred_final_lgbm = y_prob_final_lgbm > 0.5\n",
    "\n",
    "# Calcul des métriques finales\n",
    "api_auc = roc_auc_score(y_api, y_prob_final_lgbm)\n",
    "api_accuracy = accuracy_score(y_api, y_pred_final_lgbm)\n",
    "tn, fp, fn, tp = confusion_matrix(y_api, y_pred_final_lgbm).ravel()\n",
    "api_cost = fp + 10 * fn  \n",
    "\n",
    "print(\"Métriques du modèle lightgbm final avec les meilleurs paramètres sur les données test API:\")\n",
    "print(f\"AUC: {api_auc:.4f}\")\n",
    "print(f\"Accuracy: {api_accuracy:.4f}\")\n",
    "print(f\"Business Score: {api_cost:.4f}\")\n",
    "\n",
    "# Enregistrement des métriques finales dans MLflow\n",
    "with mlflow.start_run():\n",
    "    mlflow.log_metrics({\"Final AUC_t lightgbm\": api_auc, \n",
    "                        \"Final Accuracy_t lightgbm\": api_accuracy, \n",
    "                        \"Final Business Score_t lightgbm\": api_cost})\n",
    "'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

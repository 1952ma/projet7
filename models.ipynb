{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\OneDrive\\Documents\\projet7\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de X_train_eval: (3075, 625)\n",
      "Taille de y_train_eval: (3075,)\n",
      "Taille de X_api: (3075, 625)\n",
      "Taille de y_api: (3075,)\n",
      "Taille de X_final: (301357, 625)\n",
      "Taille de y_final: (301357,)\n"
     ]
    }
   ],
   "source": [
    "#import des bibliothèques \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import optuna\n",
    "import mlflow\n",
    "import joblib\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Chargement des données depuis `df_clean_imputed`\n",
    "df_clean_imputed = pd.read_csv('df_clean_imputed.csv')  # Adapter avec le chemin correct\n",
    "\n",
    "# Séparer les features (X) et la cible (y)\n",
    "X = df_clean_imputed.drop(columns=['TARGET'])  \n",
    "y = df_clean_imputed['TARGET']\n",
    "\n",
    "# Première division : 1% pour l'entraînement et validation (X_train_eval, y_train_eval) et 99% pour le reste\n",
    "X_train_eval, X_remaining, y_train_eval, y_remaining = train_test_split(\n",
    "    X, y,\n",
    "    train_size=0.01,\n",
    "    stratify=y,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Deuxième division : 1% pour l'API (X_api, y_api) et 98% pour le jeu final\n",
    "X_api, X_final, y_api, y_final = train_test_split(\n",
    "    X_remaining, y_remaining,\n",
    "    train_size=0.01 / 0.99,  # Calculé pour obtenir 1% de l'original sur les données restantes\n",
    "    stratify=y_remaining,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Vérification des dimensions pour confirmation\n",
    "print(\"Taille de X_train_eval:\", X_train_eval.shape)\n",
    "print(\"Taille de y_train_eval:\", y_train_eval.shape)\n",
    "print(\"Taille de X_api:\", X_api.shape)\n",
    "print(\"Taille de y_api:\", y_api.shape)\n",
    "print(\"Taille de X_final:\", X_final.shape)\n",
    "print(\"Taille de y_final:\", y_final.shape)\n",
    "\n",
    "# X_train_eval et y_train_eval : Utilisés pour l'entraînement et la validation des modèles\n",
    "# X_api et y_api : Échantillon pour tester l'API\n",
    "# X_final et y_final : Jeu de données final pour évaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_eval.to_csv('X_train_eval2.csv', index=False)\n",
    "y_train_eval.to_csv('y_train_eval2.csv', index=False)\n",
    "X_api.to_csv('X_api.csv', index=False)\n",
    "y_api.to_csv('y_api.csv', index=False)\n",
    "X_final.to_csv('X_final2.csv', index=False)\n",
    "y_final.to_csv('y_final2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['scaler.joblib']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Standardisation des données\n",
    "scaler = StandardScaler()\n",
    "X_train_eval_scaled = scaler.fit_transform(X_train_eval)\n",
    "X_final_scaled = scaler.transform(X_final)\n",
    "\n",
    "# Enregistrement du scaler pour une utilisation future via API\n",
    "joblib.dump(scaler, 'scaler.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des bibliothèques nécessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import optuna\n",
    "import mlflow\n",
    "import time\n",
    "import logging\n",
    "\n",
    "# Configuration initiale\n",
    "logging.getLogger('optuna').setLevel(logging.CRITICAL)\n",
    "mlflow.set_experiment(\"Comparaison_de_Modèles\")\n",
    "start_time = time.time()\n",
    "results = []\n",
    "nb_runs = 5\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "smote = SMOTE()\n",
    "\n",
    "# Chargement des données\n",
    "X_train_eval = pd.read_csv('X_train_eval.csv')\n",
    "y_train_eval = pd.read_csv('y_train_eval.csv').values.ravel()\n",
    "X_final = pd.read_csv('X_final.csv')\n",
    "y_final = pd.read_csv('y_final.csv').values.ravel()\n",
    "\n",
    "# Fonction pour le calcul du score de coût métier\n",
    "def cost_metric(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return fp + 10 * fn\n",
    "\n",
    "# Optimisation du seuil\n",
    "def optimize_threshold(y_true, y_prob):\n",
    "    thresholds = np.linspace(0.1, 0.9, 100)\n",
    "    best_threshold, best_score = 0.5, float('inf')\n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "        score = cost_metric(y_true, y_pred)\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_threshold = threshold\n",
    "    return best_threshold, best_score\n",
    "\n",
    "# Fonction d'optimisation pour Logistic Regression\n",
    "def logistic_regression_optimization(trial):\n",
    "    with mlflow.start_run(run_name=\"Optimisation_Régression_Logistique\"):\n",
    "        # Définition du modèle avec des hyperparamètres optimisés\n",
    "        model = LogisticRegression(\n",
    "            C=trial.suggest_float('C', 50, 200, log=True),\n",
    "            solver=trial.suggest_categorical('solver', ['liblinear', 'lbfgs']),\n",
    "            max_iter=trial.suggest_int('max_iter', 100, 1000),\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        auc_scores, acc_scores, cost_scores, thresholds = [], [], [], []\n",
    "\n",
    "        for train_idx, val_idx in cv.split(X_train_eval, y_train_eval):\n",
    "            X_train, X_val = X_train_eval.iloc[train_idx], X_train_eval.iloc[val_idx]\n",
    "            y_train, y_val = y_train_eval[train_idx], y_train_eval[val_idx]\n",
    "\n",
    "            X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "            model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "            y_prob = model.predict_proba(X_val)[:, 1]\n",
    "            threshold, _ = optimize_threshold(y_val, y_prob)\n",
    "            thresholds.append(threshold)\n",
    "            \n",
    "            y_pred = (y_prob >= threshold).astype(int)\n",
    "            auc_scores.append(roc_auc_score(y_val, y_prob))\n",
    "            acc_scores.append(accuracy_score(y_val, y_pred))\n",
    "            cost_scores.append(cost_metric(y_val, y_pred))\n",
    "\n",
    "        # Moyenne des scores et seuil optimal\n",
    "        auc, acc, cost = np.mean(auc_scores), np.mean(acc_scores), np.mean(cost_scores)\n",
    "        optimal_threshold = np.mean(thresholds)\n",
    "\n",
    "        # Enregistrement dans MLflow\n",
    "        mlflow.log_params({\"C\": model.C, \"solver\": model.solver, \"max_iter\": model.max_iter, \"threshold\": optimal_threshold})\n",
    "        mlflow.log_metrics({\"AUC\": auc, \"Accuracy\": acc, \"Business_Score\": cost})\n",
    "        \n",
    "        # Enregistrement des résultats\n",
    "        results.append({\"Model\": \"Logistic Regression\", \"AUC\": auc, \"Accuracy\": acc, \"Business Score\": cost, \"Threshold\": optimal_threshold})\n",
    "        return cost\n",
    "\n",
    "# Fonction d'optimisation pour Random Forest\n",
    "def random_forest_optimization(trial):\n",
    "    with mlflow.start_run(run_name=\"Optimisation_Random_Forest\"):\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=trial.suggest_int('n_estimators', 50, 300),\n",
    "            max_depth=trial.suggest_int('max_depth', 5, 20),\n",
    "            min_samples_split=trial.suggest_int('min_samples_split', 2, 10),\n",
    "            min_samples_leaf=trial.suggest_int('min_samples_leaf', 1, 5),\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        auc_scores, acc_scores, cost_scores, thresholds = [], [], [], []\n",
    "\n",
    "        for train_idx, val_idx in cv.split(X_train_eval, y_train_eval):\n",
    "            X_train, X_val = X_train_eval.iloc[train_idx], X_train_eval.iloc[val_idx]\n",
    "            y_train, y_val = y_train_eval[train_idx], y_train_eval[val_idx]\n",
    "\n",
    "            X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "            model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "            y_prob = model.predict_proba(X_val)[:, 1]\n",
    "            threshold, _ = optimize_threshold(y_val, y_prob)\n",
    "            thresholds.append(threshold)\n",
    "            \n",
    "            y_pred = (y_prob >= threshold).astype(int)\n",
    "            auc_scores.append(roc_auc_score(y_val, y_prob))\n",
    "            acc_scores.append(accuracy_score(y_val, y_pred))\n",
    "            cost_scores.append(cost_metric(y_val, y_pred))\n",
    "\n",
    "        auc, acc, cost = np.mean(auc_scores), np.mean(acc_scores), np.mean(cost_scores)\n",
    "        optimal_threshold = np.mean(thresholds)\n",
    "\n",
    "        # Enregistrement dans MLflow\n",
    "        mlflow.log_params({\"n_estimators\": model.n_estimators, \"max_depth\": model.max_depth,\n",
    "                           \"min_samples_split\": model.min_samples_split, \"min_samples_leaf\": model.min_samples_leaf,\n",
    "                           \"threshold\": optimal_threshold})\n",
    "        mlflow.log_metrics({\"AUC\": auc, \"Accuracy\": acc, \"Business_Score\": cost})\n",
    "\n",
    "        results.append({\"Model\": \"Random Forest\", \"AUC\": auc, \"Accuracy\": acc, \"Business Score\": cost, \"Threshold\": optimal_threshold})\n",
    "        return cost\n",
    "\n",
    "# Fonction d'optimisation pour LightGBM\n",
    "def lightgbm_optimization(trial):\n",
    "    with mlflow.start_run(run_name=\"Optimisation_LightGBM\"):\n",
    "        model = lgb.LGBMClassifier(\n",
    "            num_leaves=trial.suggest_int('num_leaves', 20, 150),\n",
    "            max_depth=trial.suggest_int('max_depth', 5, 20),\n",
    "            learning_rate=trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "            n_estimators=trial.suggest_int('n_estimators', 50, 300),\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        auc_scores, acc_scores, cost_scores, thresholds = [], [], [], []\n",
    "\n",
    "        for train_idx, val_idx in cv.split(X_train_eval, y_train_eval):\n",
    "            X_train, X_val = X_train_eval.iloc[train_idx], X_train_eval.iloc[val_idx]\n",
    "            y_train, y_val = y_train_eval[train_idx], y_train_eval[val_idx]\n",
    "\n",
    "            X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "            model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "            y_prob = model.predict_proba(X_val)[:, 1]\n",
    "            threshold, _ = optimize_threshold(y_val, y_prob)\n",
    "            thresholds.append(threshold)\n",
    "            \n",
    "            y_pred = (y_prob >= threshold).astype(int)\n",
    "            auc_scores.append(roc_auc_score(y_val, y_prob))\n",
    "            acc_scores.append(accuracy_score(y_val, y_pred))\n",
    "            cost_scores.append(cost_metric(y_val, y_pred))\n",
    "\n",
    "        auc, acc, cost = np.mean(auc_scores), np.mean(acc_scores), np.mean(cost_scores)\n",
    "        optimal_threshold = np.mean(thresholds)\n",
    "\n",
    "        # Enregistrement dans MLflow\n",
    "        mlflow.log_params({\"num_leaves\": model.num_leaves, \"max_depth\": model.max_depth,\n",
    "                           \"learning_rate\": model.learning_rate, \"n_estimators\": model.n_estimators,\n",
    "                           \"threshold\": optimal_threshold})\n",
    "        mlflow.log_metrics({\"AUC\": auc, \"Accuracy\": acc, \"Business_Score\": cost})\n",
    "\n",
    "        results.append({\"Model\": \"LightGBM\", \"AUC\": auc, \"Accuracy\": acc, \"Business Score\": cost, \"Threshold\": optimal_threshold})\n",
    "        return cost\n",
    "\n",
    "# Optimisation des modèles\n",
    "optuna.create_study(direction='minimize').optimize(logistic_regression_optimization, n_trials=nb_runs)\n",
    "optuna.create_study(direction='minimize').optimize(random_forest_optimization, n_trials=nb_runs)\n",
    "optuna.create_study(direction='minimize').optimize(lightgbm_optimization, n_trials=nb_runs)\n",
    "\n",
    "# Tri des résultats pour obtenir le meilleur modèle\n",
    "results_df = pd.DataFrame(results)\n",
    "best_model = results_df.sort_values(by=['Business Score', 'AUC', 'Accuracy']).iloc[0]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraînement des modèles finaux avec les meilleurs paramètres\n",
    "# On récupère le meilleur modèle et les meilleurs paramètres trouvés\n",
    "\n",
    "# Logistique : \n",
    "logreg_best_params = {\n",
    "    \"C\": best_model['C'],\n",
    "    \"solver\": best_model['solver'],\n",
    "    \"max_iter\": best_model['max_iter']\n",
    "}\n",
    "logreg_model = LogisticRegression(**logreg_best_params)\n",
    "logreg_model.fit(X_final, y_final)\n",
    "y_logreg_pred = logreg_model.predict_proba(X_final)[:, 1]\n",
    "logreg_threshold = best_model['Threshold']\n",
    "logreg_final_pred = (y_logreg_pred >= logreg_threshold).astype(int)\n",
    "\n",
    "# Random Forest : \n",
    "rf_best_params = {\n",
    "    \"n_estimators\": best_model['n_estimators'],\n",
    "    \"max_depth\": best_model['max_depth'],\n",
    "    \"min_samples_split\": best_model['min_samples_split'],\n",
    "    \"min_samples_leaf\": best_model['min_samples_leaf']\n",
    "}\n",
    "rf_model = RandomForestClassifier(**rf_best_params)\n",
    "rf_model.fit(X_final, y_final)\n",
    "y_rf_pred = rf_model.predict_proba(X_final)[:, 1]\n",
    "rf_threshold = best_model['Threshold']\n",
    "rf_final_pred = (y_rf_pred >= rf_threshold).astype(int)\n",
    "\n",
    "# LightGBM : \n",
    "lgb_best_params = {\n",
    "    \"num_leaves\": best_model['num_leaves'],\n",
    "    \"max_depth\": best_model['max_depth'],\n",
    "    \"learning_rate\": best_model['learning_rate'],\n",
    "    \"n_estimators\": best_model['n_estimators']\n",
    "}\n",
    "lgb_model = lgb.LGBMClassifier(**lgb_best_params)\n",
    "lgb_model.fit(X_final, y_final)\n",
    "y_lgb_pred = lgb_model.predict_proba(X_final)[:, 1]\n",
    "lgb_threshold = best_model['Threshold']\n",
    "lgb_final_pred = (y_lgb_pred >= lgb_threshold).astype(int)\n",
    "\n",
    "# Comparaison finale des modèles\n",
    "final_results = {\n",
    "    \"Logistic Regression AUC\": roc_auc_score(y_final, y_logreg_pred),\n",
    "    \"Random Forest AUC\": roc_auc_score(y_final, y_rf_pred),\n",
    "    \"LightGBM AUC\": roc_auc_score(y_final, y_lgb_pred),\n",
    "}\n",
    "print(final_results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "import mlflow\n",
    "\n",
    "# Fonction pour le calcul du score de coût métier\n",
    "def cost_metric(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return fp + 10 * fn\n",
    "\n",
    "# Fonction pour optimiser le seuil\n",
    "def optimize_threshold(y_true, y_prob):\n",
    "    thresholds = np.linspace(0.1, 0.9, 100)\n",
    "    best_threshold, best_score = 0.5, float('inf')\n",
    "    for threshold in thresholds:\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "        score = cost_metric(y_true, y_pred)\n",
    "        if score < best_score:\n",
    "            best_score = score\n",
    "            best_threshold = threshold\n",
    "    return best_threshold, best_score\n",
    "\n",
    "# Fonction de comparaison finale des modèles\n",
    "def compare_models(y_true, model_results):\n",
    "    # On calcule les scores AUC et Business pour chaque modèle\n",
    "    comparison_results = []\n",
    "    for model_name, model_data in model_results.items():\n",
    "        # Récupération des prédictions finales et du seuil optimisé\n",
    "        y_prob = model_data['model'].predict_proba(X_final)[:, 1]\n",
    "        threshold = model_data['threshold']\n",
    "        y_pred = (y_prob >= threshold).astype(int)\n",
    "        \n",
    "        # Calcul des métriques\n",
    "        auc = roc_auc_score(y_true, y_prob)\n",
    "        business_score = cost_metric(y_true, y_pred)\n",
    "        \n",
    "        # Sauvegarder les résultats pour la comparaison\n",
    "        comparison_results.append({\n",
    "            'Model': model_name,\n",
    "            'AUC': auc,\n",
    "            'Business Score': business_score,\n",
    "            'Threshold': threshold\n",
    "        })\n",
    "    \n",
    "    # Convertir les résultats en DataFrame pour un meilleur affichage\n",
    "    comparison_df = pd.DataFrame(comparison_results)\n",
    "    \n",
    "    # Trier en fonction de AUC (descendant) et Business Score (ascendant)\n",
    "    comparison_df_sorted = comparison_df.sort_values(by=['Business Score', 'AUC'], ascending=[True, False])\n",
    "    \n",
    "    return comparison_df_sorted\n",
    "\n",
    "# Résultats de l'entraînement final pour chaque modèle\n",
    "model_results = {}\n",
    "\n",
    "# 1. Logistic Regression\n",
    "logreg_best_params = {\n",
    "    \"C\": 100,  # Remplacez avec les meilleurs paramètres trouvés\n",
    "    \"solver\": 'liblinear',  # Remplacez avec les meilleurs paramètres trouvés\n",
    "    \"max_iter\": 1000  # Remplacez avec les meilleurs paramètres trouvés\n",
    "}\n",
    "logreg_model = LogisticRegression(**logreg_best_params)\n",
    "logreg_model.fit(X_final, y_final)\n",
    "logreg_best_threshold = 0.3  # Remplacez avec le meilleur seuil trouvé\n",
    "model_results['Logistic Regression'] = {\n",
    "    'model': logreg_model,\n",
    "    'threshold': logreg_best_threshold\n",
    "}\n",
    "\n",
    "# 2. Random Forest\n",
    "rf_best_params = {\n",
    "    \"n_estimators\": 100,  # Remplacez avec les meilleurs paramètres trouvés\n",
    "    \"max_depth\": 10,  # Remplacez avec les meilleurs paramètres trouvés\n",
    "    \"min_samples_split\": 2,  # Remplacez avec les meilleurs paramètres trouvés\n",
    "    \"min_samples_leaf\": 1  # Remplacez avec les meilleurs paramètres trouvés\n",
    "}\n",
    "rf_model = RandomForestClassifier(**rf_best_params)\n",
    "rf_model.fit(X_final, y_final)\n",
    "rf_best_threshold = 0.35  # Remplacez avec le meilleur seuil trouvé\n",
    "model_results['Random Forest'] = {\n",
    "    'model': rf_model,\n",
    "    'threshold': rf_best_threshold\n",
    "}\n",
    "\n",
    "# 3. LightGBM\n",
    "lgb_best_params = {\n",
    "    \"num_leaves\": 50,  # Remplacez avec les meilleurs paramètres trouvés\n",
    "    \"max_depth\": 10,  # Remplacez avec les meilleurs paramètres trouvés\n",
    "    \"learning_rate\": 0.05,  # Remplacez avec les meilleurs paramètres trouvés\n",
    "    \"n_estimators\": 100  # Remplacez avec les meilleurs paramètres trouvés\n",
    "}\n",
    "lgb_model = lgb.LGBMClassifier(**lgb_best_params)\n",
    "lgb_model.fit(X_final, y_final)\n",
    "lgb_best_threshold = 0.3  # Remplacez avec le meilleur seuil trouvé\n",
    "model_results['LightGBM'] = {\n",
    "    'model': lgb_model,\n",
    "    'threshold': lgb_best_threshold\n",
    "}\n",
    "\n",
    "# Comparaison des modèles\n",
    "final_comparison = compare_models(y_final, model_results)\n",
    "\n",
    "# Affichage des résultats triés\n",
    "print(final_comparison)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import des bibliothèques nécessaires\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import optuna\n",
    "import mlflow\n",
    "import time\n",
    "import logging\n",
    "\n",
    "# Configuration initiale\n",
    "logging.getLogger('optuna').setLevel(logging.CRITICAL)\n",
    "mlflow.set_experiment(\"Comparaison_de_Modèles\")\n",
    "start_time = time.time()\n",
    "results = []\n",
    "nb_runs = 5\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "smote = SMOTE()\n",
    "\n",
    "# Chargement des données\n",
    "X_train_eval = pd.read_csv('X_train_eval.csv')\n",
    "y_train_eval = pd.read_csv('y_train_eval.csv').values.ravel()\n",
    "X_final = pd.read_csv('X_final.csv')\n",
    "y_final = pd.read_csv('y_final.csv').values.ravel()\n",
    "\n",
    "# Fonction pour le calcul du score de coût métier\n",
    "def cost_metric(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return fp + 10 * fn\n",
    "\n",
    "# Enregistrement des meilleurs modèles et hyperparamètres pour chaque modèle\n",
    "best_model_results = {}\n",
    "\n",
    "# 1. Régression Logistique\n",
    "def logistic_regression_optimization(trial):\n",
    "    with mlflow.start_run(run_name=\"Régression_Logistique\"):\n",
    "        # Définir le modèle avec des hyperparamètres optimisables\n",
    "        model = LogisticRegression(\n",
    "            C=trial.suggest_float('C', 50, 200, log=True),\n",
    "            solver=trial.suggest_categorical('solver', ['liblinear', 'lbfgs']),\n",
    "            max_iter=trial.suggest_int('max_iter', 100, 1000),\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        auc_scores, acc_scores, cost_scores = [], [], []\n",
    "\n",
    "        # Boucle de cross-validation\n",
    "        for train_idx, val_idx in cv.split(X_train_eval, y_train_eval):\n",
    "            X_train, X_val = X_train_eval.iloc[train_idx], X_train_eval.iloc[val_idx]\n",
    "            y_train, y_val = y_train_eval[train_idx], y_train_eval[val_idx]\n",
    "\n",
    "            # Application de SMOTE\n",
    "            X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "            model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "            y_prob = model.predict_proba(X_val)[:, 1]\n",
    "            y_pred = (y_prob > 0.5).astype(int)\n",
    "\n",
    "            # Calcul des métriques\n",
    "            auc_scores.append(roc_auc_score(y_val, y_prob))\n",
    "            acc_scores.append(accuracy_score(y_val, y_pred))\n",
    "            cost_scores.append(cost_metric(y_val, y_pred))\n",
    "\n",
    "        # Moyenne des scores\n",
    "        auc, acc, cost = np.mean(auc_scores), np.mean(acc_scores), np.mean(cost_scores)\n",
    "        \n",
    "        # Enregistrement dans MLflow\n",
    "        mlflow.log_params({\"C\": model.C, \"solver\": model.solver, \"max_iter\": model.max_iter})\n",
    "        mlflow.log_metrics({\"AUC\": auc, \"Accuracy\": acc, \"Business_Score\": cost})\n",
    "        \n",
    "        # Enregistrement des résultats\n",
    "        results.append({\"Model\": \"Logistic Regression\", \"AUC\": auc, \"Accuracy\": acc, \"Business Score\": cost})\n",
    "        return cost\n",
    "\n",
    "# 2. Random Forest\n",
    "def random_forest_optimization(trial):\n",
    "    with mlflow.start_run(run_name=\"Random_Forest\"):\n",
    "        model = RandomForestClassifier(\n",
    "            n_estimators=trial.suggest_int('n_estimators', 50, 300),\n",
    "            max_depth=trial.suggest_int('max_depth', 5, 20),\n",
    "            min_samples_split=trial.suggest_int('min_samples_split', 2, 10),\n",
    "            min_samples_leaf=trial.suggest_int('min_samples_leaf', 1, 5),\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        auc_scores, acc_scores, cost_scores = [], [], []\n",
    "\n",
    "        for train_idx, val_idx in cv.split(X_train_eval, y_train_eval):\n",
    "            X_train, X_val = X_train_eval.iloc[train_idx], X_train_eval.iloc[val_idx]\n",
    "            y_train, y_val = y_train_eval[train_idx], y_train_eval[val_idx]\n",
    "\n",
    "            X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "            model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "            y_prob = model.predict_proba(X_val)[:, 1]\n",
    "            y_pred = (y_prob > 0.5).astype(int)\n",
    "\n",
    "            auc_scores.append(roc_auc_score(y_val, y_prob))\n",
    "            acc_scores.append(accuracy_score(y_val, y_pred))\n",
    "            cost_scores.append(cost_metric(y_val, y_pred))\n",
    "\n",
    "        auc, acc, cost = np.mean(auc_scores), np.mean(acc_scores), np.mean(cost_scores)\n",
    "        \n",
    "        # Enregistrement dans MLflow\n",
    "        mlflow.log_params({\"n_estimators\": model.n_estimators, \"max_depth\": model.max_depth,\n",
    "                           \"min_samples_split\": model.min_samples_split, \"min_samples_leaf\": model.min_samples_leaf})\n",
    "        mlflow.log_metrics({\"AUC\": auc, \"Accuracy\": acc, \"Business_Score\": cost})\n",
    "\n",
    "        results.append({\"Model\": \"Random Forest\", \"AUC\": auc, \"Accuracy\": acc, \"Business Score\": cost})\n",
    "        return cost\n",
    "\n",
    "# 3. LightGBM\n",
    "def lightgbm_optimization(trial):\n",
    "    with mlflow.start_run(run_name=\"LightGBM\"):\n",
    "        model = lgb.LGBMClassifier(\n",
    "            num_leaves=trial.suggest_int('num_leaves', 20, 150),\n",
    "            max_depth=trial.suggest_int('max_depth', 5, 20),\n",
    "            learning_rate=trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "            n_estimators=trial.suggest_int('n_estimators', 50, 300),\n",
    "            random_state=42\n",
    "        )\n",
    "        \n",
    "        auc_scores, acc_scores, cost_scores = [], [], []\n",
    "\n",
    "        for train_idx, val_idx in cv.split(X_train_eval, y_train_eval):\n",
    "            X_train, X_val = X_train_eval.iloc[train_idx], X_train_eval.iloc[val_idx]\n",
    "            y_train, y_val = y_train_eval[train_idx], y_train_eval[val_idx]\n",
    "\n",
    "            X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "            model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "            y_prob = model.predict_proba(X_val)[:, 1]\n",
    "            y_pred = (y_prob > 0.5).astype(int)\n",
    "\n",
    "            auc_scores.append(roc_auc_score(y_val, y_prob))\n",
    "            acc_scores.append(accuracy_score(y_val, y_pred))\n",
    "            cost_scores.append(cost_metric(y_val, y_pred))\n",
    "\n",
    "        auc, acc, cost = np.mean(auc_scores), np.mean(acc_scores), np.mean(cost_scores)\n",
    "        \n",
    "        # Enregistrement dans MLflow\n",
    "        mlflow.log_params({\"num_leaves\": model.num_leaves, \"max_depth\": model.max_depth,\n",
    "                           \"learning_rate\": model.learning_rate, \"n_estimators\": model.n_estimators})\n",
    "        mlflow.log_metrics({\"AUC\": auc, \"Accuracy\": acc, \"Business_Score\": cost})\n",
    "\n",
    "        results.append({\"Model\": \"LightGBM\", \"AUC\": auc, \"Accuracy\": acc, \"Business Score\": cost})\n",
    "        return cost\n",
    "\n",
    "# Optimisation des modèles avec Optuna\n",
    "print(\"Optimisation : Logistic Regression\")\n",
    "optuna.create_study(direction='minimize').optimize(logistic_regression_optimization, n_trials=nb_runs)\n",
    "\n",
    "print(\"Optimisation : Random Forest\")\n",
    "optuna.create_study(direction='minimize').optimize(random_forest_optimization, n_trials=nb_runs)\n",
    "\n",
    "print(\"Optimisation : LightGBM\")\n",
    "optuna.create_study(direction='minimize').optimize(lightgbm_optimization, n_trials=nb_runs)\n",
    "\n",
    "# Résultats finaux et modèle recommandé\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df_sorted = results_df.sort_values(by=['Business Score', 'AUC', 'Accuracy'], ascending=[True, False, False])\n",
    "print(\"\\nTop Modèles : Comparaison:\\n\", results_df_sorted.head(3))\n",
    "\n",
    "best_model = results_df_sorted.iloc[0]\n",
    "print(f\"\\nLe modèle recommandé pour la production est : {best_model['Model']} avec AUC: {best_model['AUC']}, Accuracy: {best_model['Accuracy']}, et Business Score: {best_model['Business Score']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import des bibliothèques \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix, roc_curve\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from imblearn.over_sampling import SMOTE\n",
    "import optuna\n",
    "import mlflow\n",
    "import joblib\n",
    "import time\n",
    "import matplotlib.pyplot as plt\n",
    "import logging\n",
    "\n",
    "#la configuration initiale\n",
    "logging.getLogger('optuna').setLevel(logging.CRITICAL)\n",
    "mlflow.set_experiment(\"Modèles_Comparaison\")\n",
    "start_time = time.time()\n",
    "results = []\n",
    "nb_runs = 5\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "smote = SMOTE()\n",
    "\n",
    "#chargement des données\n",
    "X_train_eval = pd.read_csv('X_train_eval.csv')\n",
    "y_train_eval = pd.read_csv('y_train_eval.csv').values.ravel()\n",
    "X_final = pd.read_csv('X_final.csv')\n",
    "y_final = pd.read_csv('y_final.csv').values.ravel()\n",
    "\n",
    "# Fonction pour le calcul du score de coût métier\n",
    "def cost_metric(y_true, y_pred):\n",
    "    tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
    "    return fp + 10 * fn\n",
    "\n",
    "# Enregistrement des meilleurs modèles et hyperparamètres pour chaque modèle\n",
    "best_model_results = {}\n",
    "\n",
    "# 1. Régression Logistique\n",
    "def logistic_regression_optimization(trial):\n",
    "    model = LogisticRegression(\n",
    "        C=trial.suggest_float('C', 50, 200, log=True),\n",
    "        solver=trial.suggest_categorical('solver', ['liblinear', 'lbfgs']),\n",
    "        max_iter=trial.suggest_int('max_iter', 100, 1000),\n",
    "        random_state=42\n",
    "    )\n",
    "    auc_scores, acc_scores, cost_scores = [], [], []\n",
    "\n",
    "    for train_idx, val_idx in cv.split(X_train_eval, y_train_eval):\n",
    "        X_train, X_val = X_train_eval.iloc[train_idx], X_train_eval.iloc[val_idx]\n",
    "        y_train, y_val = y_train_eval[train_idx], y_train_eval[val_idx]\n",
    "\n",
    "        X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "        model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "        y_prob = model.predict_proba(X_val)[:, 1]\n",
    "        y_pred = (y_prob > 0.5).astype(int)\n",
    "\n",
    "        auc_scores.append(roc_auc_score(y_val, y_prob))\n",
    "        acc_scores.append(accuracy_score(y_val, y_pred))\n",
    "        cost_scores.append(cost_metric(y_val, y_pred))\n",
    "\n",
    "    auc, acc, cost = np.mean(auc_scores), np.mean(acc_scores), np.mean(cost_scores)\n",
    "    results.append({\"Model\": \"Logistic Regression\", \"AUC\": auc, \"Accuracy\": acc, \"Business Score\": cost})\n",
    "    return cost\n",
    "\n",
    "# 2. Random Forest\n",
    "def random_forest_optimization(trial):\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=trial.suggest_int('n_estimators', 50, 300),\n",
    "        max_depth=trial.suggest_int('max_depth', 5, 20),\n",
    "        min_samples_split=trial.suggest_int('min_samples_split', 2, 10),\n",
    "        min_samples_leaf=trial.suggest_int('min_samples_leaf', 1, 5),\n",
    "        random_state=42\n",
    "    )\n",
    "    auc_scores, acc_scores, cost_scores = [], [], []\n",
    "\n",
    "    for train_idx, val_idx in cv.split(X_train_eval, y_train_eval):\n",
    "        X_train, X_val = X_train_eval.iloc[train_idx], X_train_eval.iloc[val_idx]\n",
    "        y_train, y_val = y_train_eval[train_idx], y_train_eval[val_idx]\n",
    "\n",
    "        X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "        model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "        y_prob = model.predict_proba(X_val)[:, 1]\n",
    "        y_pred = (y_prob > 0.5).astype(int)\n",
    "\n",
    "        auc_scores.append(roc_auc_score(y_val, y_prob))\n",
    "        acc_scores.append(accuracy_score(y_val, y_pred))\n",
    "        cost_scores.append(cost_metric(y_val, y_pred))\n",
    "\n",
    "    auc, acc, cost = np.mean(auc_scores), np.mean(acc_scores), np.mean(cost_scores)\n",
    "    results.append({\"Model\": \"Random Forest\", \"AUC\": auc, \"Accuracy\": acc, \"Business Score\": cost})\n",
    "    return cost\n",
    "\n",
    "# 3. LightGBM\n",
    "def lightgbm_optimization(trial):\n",
    "    model = lgb.LGBMClassifier(\n",
    "        num_leaves=trial.suggest_int('num_leaves', 20, 150),\n",
    "        max_depth=trial.suggest_int('max_depth', 5, 20),\n",
    "        learning_rate=trial.suggest_float('learning_rate', 0.01, 0.3),\n",
    "        n_estimators=trial.suggest_int('n_estimators', 50, 300),\n",
    "        random_state=42\n",
    "    )\n",
    "    auc_scores, acc_scores, cost_scores = [], [], []\n",
    "\n",
    "    for train_idx, val_idx in cv.split(X_train_eval, y_train_eval):\n",
    "        X_train, X_val = X_train_eval.iloc[train_idx], X_train_eval.iloc[val_idx]\n",
    "        y_train, y_val = y_train_eval[train_idx], y_train_eval[val_idx]\n",
    "\n",
    "        X_train_smote, y_train_smote = smote.fit_resample(X_train, y_train)\n",
    "        model.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "        y_prob = model.predict_proba(X_val)[:, 1]\n",
    "        y_pred = (y_prob > 0.5).astype(int)\n",
    "\n",
    "        auc_scores.append(roc_auc_score(y_val, y_prob))\n",
    "        acc_scores.append(accuracy_score(y_val, y_pred))\n",
    "        cost_scores.append(cost_metric(y_val, y_pred))\n",
    "\n",
    "    auc, acc, cost = np.mean(auc_scores), np.mean(acc_scores), np.mean(cost_scores)\n",
    "    results.append({\"Model\": \"LightGBM\", \"AUC\": auc, \"Accuracy\": acc, \"Business Score\": cost})\n",
    "    return cost\n",
    "\n",
    "# Optimisation des modèles\n",
    "print(\"Optimizing Logistic Regression\")\n",
    "optuna.create_study(direction='minimize').optimize(logistic_regression_optimization, n_trials=nb_runs)\n",
    "\n",
    "print(\"Optimizing Random Forest\")\n",
    "optuna.create_study(direction='minimize').optimize(random_forest_optimization, n_trials=nb_runs)\n",
    "\n",
    "print(\"Optimizing LightGBM\")\n",
    "optuna.create_study(direction='minimize').optimize(lightgbm_optimization, n_trials=nb_runs)\n",
    "\n",
    "# Enregistrement des résultats et tri pour obtenir le meilleur modèle\n",
    "results_df = pd.DataFrame(results)\n",
    "results_df_sorted = results_df.sort_values(by=['Business Score', 'AUC', 'Accuracy'], ascending=[True, False, False])\n",
    "print(\"\\nTop Models Comparison:\\n\", results_df_sorted.head(3))\n",
    "\n",
    "# Affichage du modèle recommandé\n",
    "best_model = results_df_sorted.iloc[0]\n",
    "print(f\"\\nLe modèle recommandé pour la production est {best_model['Model']} avec AUC: {best_model['AUC']}, Accuracy: {best_model['Accuracy']}, et Business Score: {best_model['Business Score']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
